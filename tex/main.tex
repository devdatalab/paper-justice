\documentclass[12pt,english]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[letterpaper]{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
\usepackage{color}
\usepackage{babel}
%\usepackage[colorinlistoftodos]{todonotes}
\usepackage{amsmath}
\usepackage{float} % required so that the [H] optin for positioning works
\usepackage{multirow}
% allow for equation numbering in align* environment
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{appendix}
\usepackage{booktabs}
\usepackage[authoryear]{natbib}
% \usepackage{lscape}
\usepackage{geometry}
\usepackage{soul} % for using \hl to highlight stuff
\usepackage{pdflscape}
\usepackage{rotating}
\usepackage{tabularx}
\doublespacing
\usepackage[unicode=true,
 bookmarks=false,
 breaklinks=false,pdfborder={0 0 1},colorlinks=true]
 {hyperref}
\hypersetup{
 allcolors=blue}
\makeatletter
\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

% for stata significance levels like: \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\)
\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
 
% Set exhibit path to current folder for compilers that need it. (DDL people need this for local compile.)
\newcommand{\HOME}{\string~}
\IfFileExists{\HOME/include.tex}{
  \newcommand{\curpath}{\HOME/ddl/justice-overleaf}
}{
  \newcommand{\curpath}{.}
}

\begin{document}

\title{ 
    \vspace{-2.0cm} 
    \textbf{
        In-group bias in the Indian judiciary \\ 
        {\Large Evidence from 5 million criminal cases}
    }
}

\author{
    {\large
        Elliott Ash, Sam Asher, Aditi Bhowmick, \\ 
        Sandeep Bhupatiraju, Daniel Chen, Tanaya Devi,  \\
        Christoph Goessmann, Paul Novosad, Bilal Siddiqi
    \unskip}
    \unskip\thanks{
        {\scriptsize 
            Author Details: Ash, ETH Zurich: ashe@ethz.ch; Asher, Imperial College London: sam.asher@imperial.ac.uk; Bhowmick, Development Data Lab: bhowmick@devdatalab.org;  Bhupatiraju: World Bank: sbhupatiraju@worldbank.org; Chen, Toulouse and World Bank: daniel.chen@iast.fr; Devi, Harvard: tdevi@g.harvard.edu; Goessmann, ETH Zurich: christoph.goessmann@gess.ethz.ch;  Novosad, Dartmouth College: paul.novosad@dartmouth.edu; Siddiqi, IDinsight: bilalmsiddiqi@gmail.com. We thank Alison Campion, Rebecca Cai, Nikhitha Cheeti, Kritarth Jha, Romina Jafarian, Ornelie Manzambi, Chetana Sabnis, and Jonathan Tan for helpful research assistance. We thank Emergent Ventures, the World Bank Research Support Budget, the World Bank Program on Data and Evidence for Justice Reform, the UC Berkeley Center for Effective Global Action, the DFID Economic Development and Institutions program, and The Bright Initiative for financial support. For helpful feedback we thank participants of the NBER Summer Institute Crime Working Group, Political Economy Seminar at ETH Zurich, Delhi School of Economics Winter School 2020, Texas Economics of Crime Workshop, Midwest International Economic Development Conference, Discrimination and Diversity Workshop at the University of East Anglia, Seminar in Applied Microeconomics Virtual Assembly and Discussion (SAMVAAD), Women in Economics and Policy seminar series, UC Berkeley Development Economics brown bag series, ACM SIGCAS Conference on Computing and Sustainable Societies (2021), German Development Economics Conference, Evidence in Governance and Politics (EGAP) seminar series, the Yale Race, Ethnicity, Gender, and Economic Justice Virtual Symposium, the Penn Center for the Advanced Study of India, and researchers at the Vidhi Center for Legal Policy.
        }
    }
}

\maketitle

\vspace{-.75cm}

\begin{abstract}
    %% 94 words
    \singlespacing \noindent
    We study judicial in-group bias in Indian criminal courts using newly collected data on over 5 million criminal case records from 2010--2018. After classifying gender and religious identity with a neural network, we exploit quasi-random assignment of cases to judges to determine whether judges favor defendants with similar identities to themselves. In the aggregate, we estimate tight zero effects of in-group bias based on shared gender or religion, including in settings where identity may be especially salient, such as when the victim and defendant have discordant identities. Proxying caste similarity with shared last names, we find a degree of in-group bias, but only among people with rare names; its aggregate impact remains small.

    \noindent \textbf{JEL codes}: J15, J16, K4, O12
\end{abstract}

\section{Introduction}

Structural inequalities across groups defined by gender, religion, and ethnicity are seen in almost all societies. Governments often try to remedy these inequalities through laws and policies, such as anti-discrimination statutes or affirmative action, which must then be enforced by the legal system. A challenging problem is that the legal system itself may have unequal representation. It remains an open question whether legal systems in developing countries are effective at pushing back against structural inequality or whether they serve to entrench it.

This paper examines bias in India's courts, asking whether judges deliver more favorable treatment to defendants who match their identities. The literature suggests that judicial bias along gender, religious, or ethnic lines is pervasive in richer countries, having been identified in a wide range of settings around the world.\footnote{See, for example, \citet{ShayoZussman2011QJE}, \citet{Didwania2018CLE}, \citet{arnold2018racial}, \citet{AbramsBertrandMullainathan2012TJoLS}, \citet{AlesinaLaFerrara2014TAER}, \citet{anwar2019jury} and others below.} However, it has not been widely studied in the courts of lower-income countries. In-group bias of this form has been identified in other contexts in India, such as among loan officers \citep{fisman2020experience}, election workers \citep{neggers2018}, and school teachers \citep{HannaLinden2012AEJEP}. But the judicial setting is of particular interest, given the premise that individuals who are discriminated against in informal settings can find recourse via equal treatment under the law \citep{sandefur2013}.

We focus on the dimensions of gender, religion, and caste, motivated by growing evidence that India's women, Muslims, and lower castes do not enjoy equal access to economic or other opportunities \citep{ito2009caste,BertrandHannaMullainathan2010JoPE,HannaLinden2012AEJEP,jayachandran2015roots,borker2017safety,anr2020mob}. In India's lower courts, unequal representation is a recognized issue. Women represent half the population but only 27\% of district court judges. Similarly, India's 200 million Muslims represent 14\% of the population but only 7\% of district court judges.\footnote{Source: eCourts data, see Table~\ref{tab:judge_sam}. We did not find a statistic for overall representation of Scheduled Castes in the judiciary, but there is some evidence that they are also underrepresented \citep{times2018obcs}.} We examine whether unequal representation in the courts has a direct effect on the judicial outcomes of women, Muslims and lower castes, in the form of judges delivering better outcomes to criminal defendants who match their identities. 

Our analysis draws upon a new dataset of 5 million criminal court cases covering 2010--2018, constructed from case records scraped from an online government repository for cases heard in India's trial courts.\footnote{The eCourts platform can be accessed at \url{https://ecourts.gov.in/}. That site hosts the case records only through a slow search engine that returns unstructured results. The data was not previously available as a structured dataset or API. } These cases are drawn from a dataset covering the universe of India's 7,000+ district and subordinate trial courts, staffed by over 80,000 judges; for context, the American judiciary is less than half as large, with 31,700 judges \citep{faqs2021}. We have released an anonymized version of the dataset, opening the door to many new analyses of the judicial process in the world's largest democracy and largest common-law legal system.\footnote{The data can be accessed at \url{https://www.devdatalab.org/judicial-data}. The complete dataset --- civil and criminal, without filtering --- contains 77 million case records.}

An initial challenge with the case data is that it does not include the identity characteristics of judges and defendants. To address this issue, we build a neural-net-based classifier to assign gender and religion based on the text of names. The classifier is trained on a collection of millions of names from the Delhi voter rolls (labeled for gender) and the National Railway Exam (labeled for religion). The deep neural net classifier is sensitive to distinctive sequences of characters in the names, allowing us to classify individuals by gender and religion with over 97\% out-of-sample accuracy on both dimensions. This accuracy is significantly higher than the standard approach of fuzzy matching.\footnote{The name classifier code is available as an open-source software package, see \url{https://github.com/devdatalab/paper-justice/tree/main/classifier}. The trained gender classifier model is also available at that link, while the religion classifier is available to researchers upon request.}  We apply the trained model to our case dataset to assign identity characteristics to judges, defendants, and victims.

Compared to gender and religion, caste identity is more complex and hierarchical, making it difficult to specify binary in-groups and out-groups; individual names are also less predictive of caste than they are of religion and gender \citep{vahini2022}. Given these limitations, we define a caste identity match as a case where the defendant's last name matches the judge's last name. This is an imperfect measure because multiple family names may reflect the same caste and certain last names may be used by members of many castes. Nevertheless, for many names, individuals in the same region who share a last name are likely to belong to the same caste.\footnote{Using the same last name to classify identity groups has predicted preferential outcomes in previous work, for instance in the banking setting \citep{fisman2017cultural}.}

We examine whether judges treat defendants differently when they share the same gender, religion, or caste.  We focus on the subset of cases filed under India's criminal codes, where acquittal and conviction rates can be interpreted as positive and negative outcomes, respectively.\footnote{We use the subset of criminal cases for which we can match a case to a judge and identify the religion and gender identity of both judge and defendant, which is about a quarter of all criminal cases, which are broadly representative across states and charges.} Given the extreme delays in India's judicial system \citep{trusts2019india, rao2019judges}, we additionally examine whether in-group judge identity affects the court's speed in reaching a decision.

We exploit the arbitrary rules by which cases are assigned to judges, generating as-good-as-random variation in judge identity. Our preferred specification includes court-year-month and charge fixed effects. This approach effectively compares the outcomes of two defendants with the same identity classification, charged under the same criminal section, in the same court and in the same month, but who are assigned to judges with different identities.\footnote{Results are robust to adding judge fixed effects (which control for variation in the severity of specific judges), though these are not expected to make a difference under random assignment of cases to judges.}

In the aggregate, we find that sharing gender, religion, or caste with a defendant makes a judge no more or less likely to deliver an acquittal. The confidence intervals rule out effect sizes that are an order of magnitude smaller than nearly all prior estimates of in-group bias based on similar identification strategies in the literature. The exception is \cite{lim2016judges}, who find little evidence of in-group gender or racial bias among judges in Texas, notably the most statistically powered study in this class before ours. The upper end of the 95\% confidence interval in our primary specification rejects a 0.6-percentage-point effect size in the worst case; studies using the same identification strategy in other contexts have routinely found bias effects ranging from 5 to 20 percentage points.\footnote{Judge demographics are not irrelevant to outcomes, however. We find that Muslim judges have a one percentage point higher acquittal rate than non-Muslim judges, and are slightly less likely to resolve a case quickly.} 

We also examine speed of decision as an outcome. We can again rule out a substantial in-group bias effect --- the 95\% confidence interval excludes a one percentage point change in either direction in the likelihood that a case is resolved within six months. However, in some specifications, we find that same-gender judges are 0.4 percentage points more likely to conclude a case within this timeframe.

Notwithstanding a null effect of in-group bias on average, bias could be activated in contexts where judge and defendant identity are more salient. We examine four special contexts that the literature suggests may prime in-group bias \citep{mullen1992ingroup,ShayoZussman2011QJE,AnwarBayerHjalmarsson2012TQJoE,Mehmood2020}. First, we examine cases where the defendant and the victim of the crime have different identities. Sharing an identity with the victim when the defendant is in an out-group could, by creating an external reference point, activate the judge's sense of opposite identity with the defendant. Second, we examine gender bias in criminal cases categorized as crimes against women, which are mostly sexual assaults and kidnappings. Here, the shared identity of gender is intrinsic to the substance of the case and may thus be more salient. Third, we examine whether in-group bias on the basis of religion is activated during or following religious festivals, which may prime religious identity. We continue to find a null bias in all of these settings.\footnote{Our null effects are notable as compared to \citet{Mehmood2020}, who find that acquittal rates in Pakistan rise by 23 percentage points (or 40\%) during Ramadan, and that they rise by 7 percentage points in India for each additional hour of fasting. \citet{Mehmood2020} do not examine differential outcomes for Muslim and non-Muslim defendants and hence do not study in-group bias. We do not exploit differences in daylight hours in our study because there is little variation in the timing of Ramadan across the 8 years in the study.}

Fourth and finally, we examine in-group bias on the basis of shared last names for the subset of the population who have uncommon last names. In this case, the shared identity with the judge is more narrowly defined, which may magnify the sense of shared identity. Here, we find economically important signs of in-group bias, though they are not statistically significant in all specifications. These effects are large for individual defendants (about a 10\% higher chance of acquittal when paired with a judge of the same last name), but remain small in aggregate because they apply to a narrow subset of defendants who both have uncommon names and are lucky enough to be assigned a judge with the same uncommon name. Nevertheless, this effect demonstrates that judges do display some degree of in-group bias, and it may also exist on other markers of caste that we do not observe.

Our estimates do not rule out bias on the basis of identity in a general sense. For example, both Muslim and non-Muslim judges could discriminate against Muslims and both male and female judges could provide unfair judgments to women (as found for Black defendants in U.S. courts by \citet{arnold2018racial} and \citet{arnold2022measuring}, for example). There could also be bias higher up the judicial pipeline: arrests and/or charges may disproportionately target Muslims, or charges brought by women may not be taken as seriously by the police. Our null estimates are nevertheless notable, as prior studies with very similar designs have found substantial degrees of in-group bias in many other settings.

In Section~\ref{sec:conc}, we discuss several reasons that bias could be small in our  setting, given its apparent ubiquity in other judicial settings and other Indian contexts. At face value, the results suggest that rule-of-law institutions and judicial norms effectively prevent favoritism for in-groups. Other factors that might influence the degree of bias include the extent that the context is adversarial or cooperative, the class distance between judge and defendant, or, as suggested by the results on uncommon last names, the overall salience of the shared identity group. 

The finding that in-group bias emerges only where identity is very salient is informative for our understanding of prior work, which consistently finds large in-group effects in the judicial domain. The most similar prior studies focus on the United States and Israel, institutional contexts where race, ethnic, or religious identity may be exceptionally salient. The U.S. incarceration system, in particular, has reproduced many aspects of the slave system that preceded it \citep{Alexander2010Jim}. With this historical legacy, it is perhaps unsurprising to find that defendant race is a highly salient feature of many U.S. criminal cases.

Another potential contributing factor could be publication bias in the social-science literature on judicial bias, such that contexts \textit{without} in-group bias are not prominently described in completed papers. To assess this possibility, we aggregate the effect sizes and standard errors from earlier papers with highly similar empirical designs to ours. Following the approach from \cite{andrews2019bias}, we find evidence consistent with a high degree of publication bias. The \citet{andrews2019bias} estimator suggests that statistically significant findings of in-group bias are about 30 times more likely to make it from conception to publication.

Our study makes four contributions. First, contrary to most of the existing literature, we demonstrate a notable absence of judicial in-group bias in an important low-income-country context with substantial religious, ethnic, and gender-based cleavages. Because the size of our sample is orders of magnitude larger than nearly all prior studies, we are able to measure this (absence of) bias much more precisely than prior work. Second, our finding of in-group bias when the reference group is small and more salient may shed light on contexts where bias may be more or less likely to occur. In particular, the large and significant bias results for Jewish versus Arab defendants in Israel, and Black versus White defendants in the U.S. (described below), are found in contexts where ethnic identity is salient to the extreme, in-groups are well-defined and recognizable, and external cross-group tensions are heightened. Third, we provide evidence that the existing body of knowledge on in-group bias in judicial settings suffers from a substantial degree of publication bias, which has implications well outside the Indian context. Fourth, we have made public a 77 million case dataset which is already enabling a range of future research projects in this domain.

Our results add to the literature on biased decision-making in the legal system. Most prior work is on the U.S. legal system, where disparities have been documented at many levels.\footnote{These include racial disparities in the execution of stop-and-frisk programs \citep{GoelRaoShroffothers2016TAoAS}, motor vehicle searches by police troopers \citep{anwar2006alternative}, bail decisions \citep{arnold2018racial,arnold2022measuring}, charge decisions \citep{RehaviStarr2014JoPE}, and judge sentence decisions \citep{Mustard2001TJoLaE,AbramsBertrandMullainathan2012TJoLS, AlesinaLaFerrara2014TAER, kastellec2013racial}. African-American judges have been found to vote differently from Caucasian-American judges on issues where minorities are disproportionately affected, such as affirmative action, racial harassment, unions, and search and seizure cases \citep{Scherer2004PSQ,ChewKelley2008WUR,Kastellec2011PRQ}. In a similar manner, a number of papers have documented the effect of judges' gender in sexual harassment cases \citep{BoydEpsteinMartin2010AJoPS,Peresie2005TYLJ}. A smaller set of papers use information on both the identity of the defendant and the decision-maker. \citet{AnwarBayerHjalmarsson2012TQJoE} look at random variation in the jury pool and find that having a Black juror in the pool decreases conviction rates for Black defendants. A similar result from Israel is documented by \citet{grossman2016descriptive}, who find that the effect of including even one Arab judge on the decision-making panel substantially influences trial outcomes of Arab defendants. \cite{Didwania2018CLE} find in-group bias in that prosecutors charge same-gender defendants with less severe offenses.} The closest paper to ours is \citet{ShayoZussman2011QJE}, who analyze the effect of assigning a Jewish versus an Arab judge in Israeli small claims court. They find robust evidence of in-group bias: Jewish judges favor Jewish defendants and/or Arab judges favor Arab defendants.

A handful of other studies use quasi-random designs to estimate in-group bias in similar fashion to us. While most of these papers report large and statistically significant pro-in-group effects, one paper finds anti-in-group bias.\footnote{\citet{gazal2010let} find positive in-group bias in bail decisions when Arab and Jewish defendants are randomly assigned to a judge of the same ethnicity. \citet{knepper2018shadow} and \citet{sloane2019racial} leverage random assignment of cases in the U.S. to judges and prosecutors respectively, finding significant in-group bias in trial outcomes. \citet{depew2017judges} exploit random assignment of judges to juvenile crimes in Louisiana and find \textit{negative} in-group bias in sentence lengths and likelihood of being placed in custody.} Of the papers we could find, only \citet{lim2016judges} find a null in-group effect of judge ethnicity or gender.


In the Indian context, there is a growing body of evidence on the legal system, mostly focusing on judicial efficacy and economic performance \citep{Chemin2009JoCE,rao2019judges}, and on corruption in the Indian Supreme Court \citep{aney2017jobs}. A recent working paper finds that judges are more prone to deny bail if they had been exposed to communal riots in early childhood \citep{bhartiroy2020}. We are aware of no prior large-scale empirical research on unequal legal treatment in India, a topic of substantial policy relevance.
Beyond the issue of in-group bias, we add to the growing literature on courts in developing countries. Well-functioning courts are widely considered a central component of effective, inclusive institutions, with judicial equity and rule of law seen as key indicators of a country’s institutional quality \citep{Rodrik2000Sicid,Le2004JoID,Rodrik2005Hoeg,pande2005institutions,Visaria2009AEJAE,lichand2014access,PonticelliAlencar2016TQJoE,world2017world}. A handful of important cross-country studies have recovered some broad stylized facts on the causes and consequences of different broad features of legal systems \citep{DjankovLaPortaLopez-de-SilanesShleifer2003QJoE,la2004judicial,LaPortaLopez-de-SilanesShleifer2008JoEL}. But largely due to a lack of data, there has been a relative paucity of within-country court- or case-level research on the delivery of justice in lower-income settings. 

The rest of the paper is organized as follows. After outlining the institutional context (Section~\ref{sec:bg}) and data sources (Section~\ref{sec:data}), we articulate our empirical approach (Section~\ref{sec:strategy}). Section~\ref{sec:results} reports the results. Section~\ref{sec:conc} compares the results to the previous literature and concludes. Replication code and data are posted in a public repository, along with a gender classification web app.\footnote{The repository can be found at \url{https://github.com/devdatalab/paper-justice/}.} 

\section{Background}
\label{sec:bg}

\subsection{Gender, Caste and Religion in India}

India's population is characterized by cross-cutting divisions between gender and religion. Women's rights and their status in society are under intense political debate. Women constitute 48\% of the population, and remain vulnerable to social practices such as female infanticide, child marriage, and dowry deaths despite existing legislation outlawing all of the above. India accounts for one third of all child marriages globally \citep{cousins2020} and nearly one third of the 142.6 million missing females in the world \citep{Erken2020}. 

Muslims in India (14\% of the population) have historically had intermediate socioeconomic outcomes worse than upper caste groups but better than lower caste groups \citep{sachar2006}. However, they have been protected by few of the policies and reservations targeted to Scheduled Castes and Tribes (17\% and 9\% of the population, respectively). In recent decades, many successful political parties have been accused of implicitly or explicitly discriminating against Muslims. The marginalized statuses of  women and Muslims in India motivate our exploration of the role of gender and religion in the context of India's criminal justice system.

\subsection{India's Court System}

India's judicial system is organized in a jurisdictional hierarchy, similar to other common-law systems. There is a Supreme Court, 25 state High Courts, and 672 district courts below them. Beneath the district courts, there are about 7000 subordinate courts. The district courts and subordinate courts (which we study here) collectively constitute India's lower judiciary. These courts represent the point of entry of almost all criminal cases in India.\footnote{We define criminal cases as all cases filed either under the Indian Penal Code Act or the Code of Criminal Procedure Act.}

These courts are staffed by over 80,000 judges. Due to common law institutions where court rulings serve as binding precedent in future cases, judges in India are effectively policymakers. Indian judges are arguably even more powerful than their U.S. counterparts because they do not share decision authority with juries, which were banned in 1959. Therefore, fair and efficient decision-making by judges is a leading issue for governance. 

Lower-court judges in India are appointed by the governor in consultation with the state high court's chief justice. At least seven years of legal practice are required as a  minimum qualification. The recruitment process entails a written examination and oral interview by a panel of higher-court judges. Judge tenure is in general well-protected, with removal by the governor only possible with the agreement of the high court. Finally,  district judges can be promoted to higher offices in the judiciary after specific numbers of years in their post.

There is an active debate in India around reforming the court system. Problems under discussion include a reputation for corruption \citep{dev2019}, a substantial backlog of cases \citep{trusts2019india}, and judicial independence \citep{economist2024}. 

\subsection{Case Assignment to Judges}

The procedure of case assignment to judges is pivotal for this study because our empirical strategy hinges on the exogenous assignment of judges to cases. To better understand the case assignment process, we consulted with several criminal lawyers who practice in India's district courts, senior research fellows at the Vidhi Center for Legal Policy, and several clerks in courts around the country. 

Criminal cases are assigned to judges as follows. First, a crime is reported at a particular local  police station, where a First Information Report (FIR) is filed. Each police station lies within the territorial jurisdiction of a specific district courthouse, which receives the case. The case is then assigned to a judge sitting in that courthouse. If there is just one judge available to see cases in the courthouse, that judge gets the case.

If there are multiple judges, a rule-based process fully determines the judge assignment. Each judge sits in a specific courtroom in a court for several months at a time. A courtroom is assigned for every police station and every charge. For example, at a given police station, every murder charge will go to the same courtroom. A larceny charge might go to a different courtroom, as might a murder charge reported at a different police station. The police station charge lists leave little room for discretion over which charges are seen by which judges.\footnote{Since 2013, there has been a random assignment lottery mechanism available through the eCourts platform, but few courts have adopted it to date. In Section~\ref{sec:strategy}, we present formal tests of the exogenous assignment of judges to cases in our dataset.} 

Judges typically spend two to three years in a given court, during which they rotate through several of the courtrooms.\footnote{Severe cases (with severity defined by the section or act under which the charge was filed) require judges with higher levels of seniority. Thus, a case in a given district may be eligible to be seen only by a subset of judges in that district.} The timing of the first court appearance is unknown when charges are filed (given judicial delays). Thus, even if a defendant or prosecutor had discretion over which police station filed the charges, the rotation of judges between courtrooms would make it difficult to target a specific judge. 

Finally, the judiciary explicitly condemns the practice of ``judge shopping'' or ``forum shopping,'' where litigants select particular judges in search of a favorable match. One of the earliest cases in which the Indian Supreme Court condemned the practice of shopping is the case of \textit{M/s Chetak Construction Ltd. v. Om Prakash \& Ors.}, 1998(4) SCC 577, where the Court ruled against a litigant trying to select a favorable judge, writing that judge shopping ``must be crushed with a heavy hand.'' This decision has been cited heavily in subsequent judgments.

In U.S. courts, a large share of criminal cases are disposed through plea bargaining, making appearance in court itself an endogenous outcome. This is not a concern in our context. While plea bargaining exists in India, fewer than 0.05\% of criminal cases end in plea bargains \citep{ncrb2018}.\footnote{Plea bargaining has only been available as a resolution mechanism in India since 2007, for cases with a maximum sentence of less than seven years. It is rarely sought by prosecutors. Legal experts suggested to us that it is rarely a good option for defendants with lawyers, who expect reasonable odds of winning at trial, and that unrepresented defendants may not be aware of the possibility of settlement.}

\section{Data}
\label{sec:data}

\subsection{Case Records}

We obtained 77 million case records from the Indian \href{https://ecourts.gov.in}{eCourts platform} --- a public system put in place by the Indian government to host summary data and full text from orders and judgments in courts across the country.\footnote{\href{https://ecourts.gov.in/ecourts_home/static/about-us.php}{https://ecourts.gov.in/ecourts\_home/static/about-us.php}, accessed Oct 14, 2020} The database includes both the PDF documents describing the judge's orders for each case (a series of typically 1--50 page documents), and a set of metadata fields that have been coded by eCourts analysts based on the case documents. We use the coded metadata only; classifying fields from the universe of PDFs will be a multi-year undertaking and is left for future work. The case metadata includes information on the filing, registration, hearing, and decision dates for each case, the petitioner and respondent names, the position of the presiding judge, the acts and sections under which the case was filed, and the final decision or disposition.\footnote{We illustrate such a record in Appendix Figure~\ref{fig:ecourts_case_view}.}

The database covers India's lower judiciary, consisting of all courts including and under the jurisdiction of District and Sessions courts and covers the period 2010--2018. Appendix Figure~\ref{fig:court_maps} maps the geographic distribution of our sample of courts, which covers the whole country. This paper focuses on cases filed either under the Indian Penal Code or the Code of Criminal Procedure, for two reasons. First, there is only a single litigant, rather than two, providing a clear definition of identity match between judge and defendant. Second, it is relatively straightforward to identify good and bad outcomes for criminal defendants, which is more difficult in civil cases. This constraint filters out 70\% of the dataset, leaving us with 23 million criminal case records (see Appendix Figure~\ref{fig:nomnoml}). 

\subsection{Judge Information}

We also obtained data on judges in all courts in the Indian lower judiciary from the eCourts platform. The data for each judge includes the judge's name, their position or designation, and the start and end date of the judge's appointment to each court.\footnote{See Appendix Figure~\ref{fig:ecourts_judge_scraping} for a sample page from which we extract the judge data. The data does not include the room in the court to which a judge is assigned.}

We joined the case-level data with the judge-level data based on the judge's designation and the initial case filing date. In this process, another 17\% of the initial observations are dropped. The remaining dataset where cases are linked to a unique judge consists of 10 million cases. From this subset, we drop all bail decisions, which are a narrow share of the data. We then drop cases where we cannot identify both defendant and judge identity (depending on whether we are analyzing religion or gender, see below). Finally, we drop cases in courts where there is only one judge in a given time period. This leaves 5.7 million cases in the religion analysis and 5.3 million in the gender analysis (see Appendix Figure~\ref{fig:nomnoml}).

\subsection{Assigning Religion and Gender Identity}

The eCourts platform does not provide demographic metadata on judges and defendants. However, gender and religious identity can be determined quite accurately in India based on individuals' names. We train a machine classifier on a large database of labeled names and then use it to assign these characteristics in the legal data.\footnote{The existing available name classifiers for gender and religion in India are expensive proprietary solutions, e.g. Namsor (namsor.com), and trials with these yielded the same or lower accuracy than our own classifier.}

We use two databases of names with associated demographic labels. To classify gender, we use a dataset of 13.7 million names with labeled gender from the Delhi voter rolls.  To classify religion, we use a database of 1.4 million names with a religion label for individuals who sat for the National Railway Exam.
  
Summary tabulations on these datasets are provided in Appendix Table~\ref{tab:training}. For gender, we observe two categories: female or male. For religion, we observe five categories: Hindu, Muslim, Christian, Buddhist, and Other. Our classifier takes a two-label specification: Muslim or non-Muslim. We do not distinguish between the non-Muslim religion categories because of their small number and because their names are not as distinctive as Muslim names. Each name record is therefore assigned two binary labels: male/female and Muslim/Non-Muslim.

The lists of labeled names from the Delhi voter rolls and National Railway Exam contain some inconsistent formatting and noise which we clean up with a set of pre-processing steps. First, Devanagari characters are transliterated to Latin. Second, we normalize capitalization, punctuation, and spacing. Salutations are preserved as they indicate gender.

Taking these pre-processed name strings as inputs, we train a neural net classifier to predict the associated identity label.  We use a bidirectional Long Short-Term Memory (LSTM) model applied directly to the sequence of name-string characters. LSTM uses a gated recurrent neural network architecture that takes as input a sequential data stream and retains a memory of previous inputs while handling new items in the sequence. LSTMs are particularly useful in understanding text sequences because the meaning of an individual letter or word is often dependent on the context of other letters and words that both precede and follow it. ``Bidirectional'' means that the classifier reads the sequence backward and forward when trying to assign a label.\footnote{In more detail, the neural net architecture is as follows. The model takes as input a sequence of characters and outputs a probability distribution across name classes. The characters are input to an embedding layer, which was initialized randomly rather than using pre-trained weights. The embedded vectors are input to a bidirectional LSTM layer, then to a single dense hidden layer, and finally to the output layer, which uses sigmoid activation to output a probability across the binary classes. To avoid overfitting, we used dropout between layers and used early stopping during training, which ceases network training when validation loss stops improving.  To account for the imbalance in the sample, we used class weights during the training. See \citet{chaturvedi2020neural} for a similar approach to infer religion from names.} 

The ability of the LSTM classifier to understand a text fragment within context greatly improves accuracy over standard fuzzy string matching methods. For instance, consider the last names \textit{Khan} and \textit{Khanna}. While the fragment \textit{KHAN} appears in both words, the addition of two letters \textit{na} following the fragment changes the meaning of the word where it is a distinctly Muslim last name without the letters \textit{na}, and a non-Muslim last name once the letters \textit{na} are added. A standard fuzzy match would fail on this example because it ignores the context (that is, the sequence of letters that appear before and after the fragment \textit{KHAN}). A counter-example are the names \textit{Fatima} and \textit{Fathimaa}, where the addition of the letters \textit{h} and \textit{a} do not change the religious classification of the name. Given these nuances, the LSTM classifier is better suited to the objective than a simple fuzzy matching function.

We use hold-out test sets within the labeled databases to assess the out-of-sample performance of the LSTM classifiers for gender and religion. The classifiers perform well on standard metrics, including our preferred metrics that adjust for imbalance in the class shares. We report balanced accuracy, which is the average accuracy (recall) for each of the two identity categories, and F1, the harmonic mean of precision and recall.\footnote{Balanced accuracy and F1 are preferred as metrics to standard accuracy when the labels to be predicted are not balanced. While gender is roughly balanced in the voter rolls data, religion is heavily imbalanced with Muslims only comprising one-tenth of the sample. Therefore a model could achieve 90\% accuracy in predicting religion by guessing non-Muslim for every individual. Balanced accuracy addresses this issue by rewarding good accuracy for both classes: we calculate the accuracy for each class and then average them, rather than taking the accuracy measure across the whole sample. F1 addresses this issue by rewarding higher precision, which penalizes false positives, and higher recall, which penalizes false negatives.}  For gender, the balanced accuracy is .98 with F1 = .98. For religion, the balanced accuracy is .98 and F1 = .99. The trained classifiers, as well as the code for training them, are available as open-source software for use by the academic community.\footnote{Both the code and the trained gender classifier are available at our GitHub repository. See \url{https://github.com/devdatalab/paper-justice/tree/main/classifier}.}

The next step is to apply the trained classifier to the eCourts case records. We have plain-text string variables for judge name and defendant name, to which we apply the same pre-processing steps as above (i.e., transliteration and normalization of punctuation/capitalization). We filter out names that are not possible to classify, which includes entries with incomplete names, or with defendants that are corporations or other non-individual entities. This results in dropping approximately 1.7 million cases where the litigants are not individuals (Appendix Figure~\ref{fig:nomnoml}). The cases retained in this step are approximately evenly distributed across states and crime categories (Appendix Table~\ref{tab:drop_sample}).

For each pre-processed judge name and defendant name, we then apply the trained classifier and form a predicted probability for gender and religion. To improve precision, we drop from our sample names which do not produce a confident classification. Comparing the confidence scores to human annotations, we see that predicted probabilities near 50\% include mostly ambiguous names. This happens for gender, for example, when the first name is missing and no salutation is included.  As a heuristic to drop these names, we set a confidence threshold that requires the model to be at least 65\% confident in a predicted gender or religion classification. For predicted probabilities between 0.35 and 0.65, the respective class is left empty. 

For judges, names tend to be complete or else include salutations. Of the 81,232 judges (22,413 unique names) appearing in the case dataset, we are able to classify 96\% according to gender (female/male) and 98\% according to religion (Muslim/non-Muslim). The information on defendant names is of lower quality, mainly due to missing first or last names. Still, we are able to classify 80\% of defendants by religion and 74\% by gender.\footnote{The proportion of defendants that can be assigned to gender and religion does not vary much by region of India (see Appendix Table~\ref{tab:lstm_by_state}).} Cases with unclassified labels are dropped from analyses requiring those labels.

To verify the accuracy of the LSTM classification within the new domain of the court records, we manually checked a random sample of names classified by the above process. An annotator manually labeled 300 names by gender and 300 names by religion, with samples stratified across states. This process confirms an accuracy of 97\% for both the gender and religion classification in the new domain; classification errors in gender and religion are thus unlikely to be a major source of bias in the analysis ahead.\footnote{As an additional automated validation, we compared the LSTM-classified Muslim defendant share by state to the state-level Muslim population shares from the 2011 Population Census. The correlation is 0.88.}

\subsection{Defining Case Outcomes}

We define the defendant's outcome (represented by $Y$ below) as a case-level indicator variable that takes the value one if the disposition is desirable for the defendant and zero otherwise. In the ``favors-defendant'' category, the main disposition is acquittal, with a couple of other equivalent dispositions such as dismissal. Tabulations on these and other dispositions are shown in Appendix Table~\ref{tab:dispositions}. The overall acquittal rate --- that is, share of dispositions favoring the defendant --- is about 15\%.

The other 85\% of cases, coded as $Y=0$, represent a somewhat broader ``does-not-favor-defendant'' category. This group includes, first, the cases where the defendant is convicted, as well as a set of equivalent outcomes indicating a guilty verdict (see Appendix Table~\ref{tab:dispositions}). Second, it includes cases that don't have a disposition at all because they have not been resolved yet. Third, a case may be closed but with an ambiguously coded disposition, which can indicate that the case was not resolved decisively (e.g., because it was transferred to another court), or else that the eCourts analyst did not write a clear classification even if one was available. An example of the latter is the disposition label ``Disposed'', which indicates that the case is closed but does not provide information on the direction of the ruling.\footnote{When we have looked manually at cases with ambiguous codings, we have found that it is often possible to determine what happened, but doing so manually is not feasible for over a million such cases.}

In our main analysis sample, 58\% of cases have decisions; of those, 40\% can be unambiguously coded as acquittal or conviction. Our main specification includes all cases --- including those without decisions and those with ambiguous codings. Missingness and decision ambiguity will affect our results only if assignment to an in-group judge affects the rate or the subset of cases that are ambiguously coded. Given that the coding appears to be a choice made by the eCourts data entry analysts, this is unlikely to take place. And indeed, we formally test and show that ambiguity and case closure are not affected by assignment to an in-group judge (Appendix Tables~\ref{tab:robust_amb_female},~\ref{tab:robust_amb_muslim}). Further, we show that our results are robust to alternative specifications along these margins, including (i) coding ambiguous or undecided outcomes as negative rather than positive; (ii) dropping either the ambiguous or the undecided cases from the data and focusing on cases with clear outcomes; or (iii) focusing on courts or charges with lower ambiguity rates (Appendix Tables \ref{tab:app_random_female}, \ref{tab:amb_random_female}, \ref{tab:app_random_muslim}, \ref{tab:amb_random_muslim}). 

Judicial delay is itself a major policy issue in India. Hence, we provide additional results where getting a decision at all is the outcome of interest. For these regressions, we define an outcome indicator for whether a decision is made on a case within six months of the case's filing date, which includes about 30\% of cases.

\subsection{Summary Statistics}

Figure~\ref{fig:summary}  presents descriptive statistics of charges and convictions by gender and religious identity of defendants, respectively.\footnote{The corresponding point estimates are reported in Appendix Tables \ref{tab:summary_gender} and \ref{tab:summary_religion}.} These summary measures are descriptive in nature, but are not directly informative of bias in the judicial system because we do not know the share of defendants who commit crimes or are guilty when charged.

Figure~\ref{fig:summary} Panel A shows that the share of women charged under all crime categories is substantially lower than their population share: men are three to six times more likely to be charged with crimes under any classification. Panel B shows that the acquittal rate varies by crime, but overall it is about 3 percentage point higher for women (the ``Total'' category, at the bottom). 

Panel C shows that Muslims are over-represented by 3\% in the universe of criminal charges. Representation changes substantially depending on the change: relative to their population share, Muslims are 11\% more likely to be charged with other crimes against women, 30\% more likely to be charged with robbery, and 62\% more likely to be charged with marriage offenses, but 5\% less likely to face charges for murder. Panel D shows that aggregate differences in acquittal rates between Muslims and non-Muslims are small.

Table~\ref{tab:judge_sam} shows descriptive statistics of judges and case outcomes in the analysis sample. About 27\% of judges are female and 6.8\% of judges are Muslim. On average, Muslim and female judges have similar acquittal, conviction and rapid decision rates to non-Muslim and male judges. Although there are similar averages across groups, we still observe significant variation across judges after adjusting for court-time and charge fixed effects.\footnote{Appendix Figure~\ref{fig:judge_resids} shows the substantial variation in the distribution of judge fixed effects for the acquittal rate after residualizing out court-time and charge fixed effects. On a base acquittal rate of 68\% (given an unambiguous decision), the IQR of the mean judge fixed effect for acquittal is [-8.0, +10.0] percentage points. Conditional on location-month and charge fixed effects, judge identity explains 10\% of the residual variation in the acquittal outcome. This is of course a lower bound on the level of discretion available to a judge, since judges do not always express discretion in the same direction.} The variation in acquittal rates for comparable case portfolios reflects the extensive discretion exercised by judges in this legal context.

Appendix Tables~\ref{tab:summary_crime_cat} and \ref{tab:summary_state} show the representativeness of our analysis sample (and subsamples used later in the paper) across state and crime categories, relative to the complete dataset of 23 million crime records. With a few exceptions, our analysis datasets are representative of the universe of criminal cases in India.

\section{Empirical Strategy}
\label{sec:strategy}

Our objective is to estimate whether defendants experience different outcomes depending on the identity of the judge presiding over their case. To estimate a causal effect of judge identity, we need to effectively control for any factors other than defendant identity that could affect both judge identity and the case outcome. 

We rely on the exogenous assignment of judges to cases, which produces as-good-as-random assignment of defendants to judges, conditional on charge and court-time pair. We formalize our empirical approach in the following subsection. For ease of exposition, we describe the empirical strategy investigating gender bias --- the specification and considerations for estimating religious identity bias are identical. Specifications used in the additional analysis on bias in contexts likely to activate identity are described with the results.\footnote{We also explored an event study specification exploiting case timing and changes in the cohort of judges sitting in each court, but we found that recently changed courts are more likely to see younger cases, violating the assumptions required for the event study analysis.}

\subsection{Random Assignment of Judges to Cases}

As with much of the prior empirical literature, judge assignment in district courts is as good as random, conditional on court-time and charge fixed effects, given rules that leave defendants and prosecutors with virtually no control over which judge oversees the case (see Section~\ref{sec:bg}). Random assignment of judges to cases addresses the concern that judges with different identities are assigned to different kinds of cases. For example, if Muslim judges could systematically choose to sit in cases with Muslim defendants who had committed less serious crimes, we might mistakenly infer in-group bias even in its absence. Alternately, Muslim defendants and judges are more likely to appear in regions of the country with more Muslims. If those regions are characterized by different crime distributions (with different acquittal rates), we might again mistakenly attribute those differences to in-group bias.

Our ideal experiment would take two defendants identical in all ways, charged with identical crimes in the same police station on the same date, and then assign them to judges with different identities. In practice, the Indian court system runs this experiment whenever a defendant is charged in a jurisdiction with multiple judges of different identities on the bench. Even if there is bias at other stages of the criminal process (e.g. in who gets charged), that would not undermine our identification strategy given the random assignment of judges.

We use a canonical regression approach to test for the effect of judge identity on case outcomes, as used by Shayo and Zussman's (2011) analysis of judicial in-group bias in Israel.  We model outcome $Y_{i}$ (e.g. 1=acquitted) for case $i$ with charge $s$, filed in court $c$ at time $t$ as:
\begin{equation}
  \label{eq:female}
  \begin{split}
    Y_{i} = \beta_{1} \text{judgeMale}_{i} + \beta_{2} \text{defMale}_{i} + \\
    \beta_{3} \text{judgeMale}_{i} * \text{defMale}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}
  \end{split}
\end{equation}
% \begin{equation} \label{eq:Muslim}
%   \begin{split}
%     Y_{i} = \beta_{1} \text{judgeNonMuslim}_{i} + \beta_{2} \text{defNonMuslim}_{i} + \\
%     \beta_{3} \text{judgeNonMuslim}_{i} * \text{defNonMuslim}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}
%   \end{split}
% \end{equation}
where judgeMale and defMale are binary variables that indicate the gender of the judge and defendant respectively. The omitted category are cases with female judges and female defendants. $\phi_{ct(i)}$ is a court-month or court-year fixed effect (based on the case filing date), and $\zeta_{s(i)}$ is an act and section fixed effect. $X_i$ includes controls for defendant religion, judge religion, and an interaction term of judge gender and defendant religion. The analysis of religious in-group bias follows the same structure, where the omitted category are Muslim judges and defendants, and $X_i$ represents controls for defendant gender, judge gender, and an interaction term of judge religion and defendant gender.

The charge section fixed effect ensures that we are comparing defendants charged with similar crimes. The court-time fixed effect ensures that we are comparing defendants who are being charged in the same court at the same time. Our primary specification uses a court-month fixed effect, while a secondary specification uses a court-year fixed effect. The court-year fixed effect allows a larger sample, at some potential bias. Judges on the bench may not hear new cases in some months because they are tied up with previous cases or away from work. It is unlikely that prosecutors or defendants can time their filings to match these absences, nor do we find evidence of disproportionate identity matching below. Court-time periods with no variation in judge identity are retained to increase the precision of fixed effects and controls, but they do not directly affect the coefficients of interest. We also test a specification with judge fixed effects, which controls for the average acquittal behavior of each individual judge.\footnote{This specification is included for completeness, but is unnecessary for identification if judges are indeed effectively assigned randomly.} Standard errors are clustered at the judge level, since judge assignment is the level of randomization.

There are three causal effects of interest. $\beta_1$ describes the causal effect on a female defendant of having a male judge assigned to her case rather than a female judge. $\beta_1 + \beta_3$ describes the causal effect on a \textit{male} defendant of having a male judge assigned to his case. The difference between these effects ($\beta_3$) is the own-gender bias --- it tells us whether individuals receive better outcomes when a judge matching their gender identity is randomly assigned to their case. Since all three causal effects are of interest, we report all three for each estimation. The coefficient meanings are analogous for the religion in-group bias tests. Appendix~\ref{appsec:balance} reports on a series of balance tests which are consistent with random assignment of judges: female defendants and petitioners are no more or less likely to be assigned a female judge, with similar results for religion.

About half the time, a case stays in the courts long enough such that the judge making the final decision is different from the one to whom the case was initially (randomly) assigned. For these decisions, we continue to use the identity characteristics of the initially assigned judge. We do not exclude these cases in our primary specification because a rapid decision is itself an outcome. Even if the filing judge does not make the final ruling on a case, they can make key decisions on the case process that influence the decision, such as allowing witnesses, admitting evidence, and determining the schedule on which the case is resolved. Either way, this choice does not drive our results, as we estimate virtually identical effects if we limit the sample to cases decided by the initially assigned judge.  

A more subtle identification issue arises in describing these matching-gender and matching-religion effects as capturing ``in-group bias.'' Our interpretation follows the prior empirical literature, where ``in-group bias'' describes a situation where defendants receive better outcomes when their identity matches the (exogenously assigned) judge's identity. A limitation of this approach, highlighted by \citet{frandsen2019judging} and \citet{canay2020use}, is that defendants from different identity groups share more characteristics than just their identity, many of which are unobserved. Further, judges from different identity groups might have correlated preferences or biases across those characteristics. For example, suppose that female defendants were more likely to have children, and that female judges were on average more lenient for defendants with children. Our empirical approach would identify in-group bias on the gender dimension. Disentangling these aspects of identity is challenging and admittedly beyond the scope of this paper. However, documenting the contextual variation in where identity matters for outcomes is a valuable first step in addressing these issues. Further, our estimates are informative of the expected impacts of making India's judge body more representative, even if any ``bias'' found is not driven by identity alone.\footnote{Another issue is ``inframarginality bias'', discussed in detail for example by \citet{canay2020use}. In brief, if judges are deciding on conviction based on some threshold (say, probability of guilt), then group bias means different thresholds across groups. Then the average group differences captured by our regression estimates are a combination of both differences in judge standards for the marginal cases around the threshold, as well as distributional differences away from the threshold. These issues are much reduced in the context of in-group bias (rather than overall bias), where such confounds would have to occur at the level of judge-defendant interactions. Further, our analysis is implicitly assuming that the inclusion of covariates work to match the defendant risk distributions at the judge-defendant-type level. Finally, again, even in the presence of such bias, our estimates are still informative about what would happen by making the judiciary more representative.}

\section{Results}
\label{sec:results}

\subsection{Effect of assignment to judge types}

The first two rows of Table~\ref{tab:random_acquittal} Panel A present the impact, for female and male defendants respectively, of being randomly assigned to a male judge --- these are $\beta_1$ and $\beta_1+\beta_3$ in Equation \ref{eq:female}. The third row shows the difference between these two coefficients ($\beta_3$), which is the own-gender bias. The outcome variable is an indicator for defendant acquittal. Columns 1--3 show results using court-month fixed effects, while Columns 4--6 use court-year fixed effects. Within each set of three columns, the second column adds additional demographic controls, while the third column adds judge fixed effects.

Male judges acquit at a similar rate to female judges, regardless of defendant gender. The own-gender bias estimate is a tight zero; the effect estimates rule out even a very small in-group bias effect of 0.5 percentage points with 95\% confidence.\footnote{Appendix Table~\ref{tab:app_random_female} shows bias effects on conviction rates (rather than acquittal rates); the estimates again are a tight zero. Appendix Table~\ref{tab:amb_random_female} shows estimates when we exclude closed cases for which we are unable to determine the outcome. We prefer the specification in Table~\ref{tab:random_acquittal}, because the inability to determine an outcome is itself an outcome. We also find no effect of gender or religious match on whether the outcome is clearly coded as acquittal or conviction (Appendix Table~\ref{tab:robust_amb_female}). Finally, we show that results are identical when we limit the sample to either courts or charges with below-median rates of the outcome being coded as ambiguous (Appendix Table~\ref{tab:robust_amb_below}).} The coefficients are stable across different fixed effect specifications, as is expected given the as-good-as-random assignment of judges to defendants. 

Appendix Table~\ref{tab:random_decision}A shows the effect of filing-judge gender on an indicator for case resolution within six months of being filed. Cases where judge and defendant match gender are at most 0.5 percentage points more likely to be resolved within six months (on a mean of 28\%). The effect is very small in magnitude, and is not robust to the inclusion of judge fixed effects.

Panel B of Table~\ref{tab:random_acquittal} presents analogous results for Muslim and non-Muslim defendants randomly assigned to Muslim and non-Muslim judges. In some specifications, we find that non-Muslim judges are less likely to acquit; but this holds equally for Muslim and non-Muslim defendants. The point estimate on in-group bias for acquittals is at most 0.3 percentage points and the estimates rule out an own-religion bias of 0.75 percentage points with 95\% confidence.\footnote{Appendix Tables~\ref{tab:app_random_muslim} and \ref{tab:amb_random_muslim} show results on conviction rates, and on acquittals with ambiguous results dropped. While we find marginally significant bias effects (in the in-group direction) in a handful of specifications, most are statistically insignificant, and the point estimate on the bias term is never higher than 0.6 percentage points. Appendix Table~\ref{tab:robust_amb_muslim} shows there is no effect of in-group bias on an indicator for an ambiguous case outcome.} Religious in-group bias is also absent in the speed of judicial decisions, nor is there any evidence that Muslim and non-Muslim judges have different rates of resolving cases (Appendix Table~\ref{tab:random_decision}B).

Given the important role that lawyers play in the judicial process, in-group bias could also depend on the identity of the lawyer.\footnote{For example, \citet{marx2019} find that ethnic patronage in rental contracts depends more on identity match between the slum chief and landlord (where the latter plays a role of arbiter) than on match between the landlord and tenant.} The names of lawyers are missing in over 90\% of cases, but we are still powered to run a bias test for the set of cases where either lawyer is observed. Appendix Tables~\ref{tab:lawyer_religion} and \ref{tab:lawyer_gender} use a similar specification to the judge-defendant models above, and show that there is no evidence of differential outcomes when the judge matches the gender or religious identity of either of the litigant's lawyers.\footnote{See Appendix \ref{appsec:balance} for balance tests related to this analysis.} 

\subsection{Judicial Bias when Identity is Salient}

Our estimates thus far show that judges do not provide substantively better outcomes for own-gender and own-religion defendants, on average.\footnote{This is contrary to most of the work in this space, which finds bias against out-group defendants regardless of the group of the victim or plaintiff, for example \citep{grossman2016descriptive}, \citep{AnwarBayerHjalmarsson2012TQJoE}, 
    \citep{gazal2010let}, \citep{sloane2019racial}, and \citep{Didwania2018CLE}.}

Some of the prior literature suggests that various identities can be made more salient by specific contexts or primes. This section examines several circumstances where gender or religious identity may become particularly salient to judges. In each circumstance, we test for additional bias by defining an indicator variable that takes the value one in a condition that activates bias. We interact this variable with every right-hand side variable in Equation \ref{eq:female}. If bias is particularly activated in this context, the interaction with the in-group bias term will be positive and significant.

We first examine the subset of cases where the victim and defendant have different identities. In these cases, when the defendant and judge are mismatched, the judge and victim will share the same gender or religious identity.\footnote{In the case of religion, 6\% of Indians are neither Muslim nor Hindu, so two non-Muslim individuals are highly likely to be in the same broad religious group but in some cases will not be.} The identity match or mismatch between judge and defendant may be particularly salient in this case \citep{BaldusWoodworthZuckermanWeiner1997CLR,FosterLeeHorowitzKing2006BSL,BaumgartnerGriggMastro2015PGI}. Column 1 of Table~\ref{tab:bias_activated} interacts an indicator for defendant-victim gender mismatch with the gender in-group bias indicator. Both the baseline bias effect and the interacted effect are null; judges do not show gender in-group bias even when the defendant and victim have different genders (only one of which is matched by the judge). Similarly, Column 2 shows that there is no additional in-group religion bias when defendant and victim have different religions.\footnote{Note that for legibility, the table only lists the in-group bias term and its interaction with the context variable, but all the terms in Equation~\ref{eq:female} are interacted with the context variable, as are the fixed effects. Appendix Tables~\ref{tab:bias_activated_all_g} and \ref{tab:bias_activated_all_r} show all of the coefficients from the regression with court-month fixed effects. Samples are smaller than in the main bias estimation because the identity of the victim can be determined (from the name) in only about half of cases.} Standard errors are larger due to the smaller sample and interaction specification, but the in-group bias effect is less than 1 percentage point in both cases.

We next look at whether male and female judges rule differently on cases classified in the criminal code as crimes against women, where judge and defendant gender identities may be particularly salient. These are about evenly split between sexual assaults and kidnappings.\footnote{One reason ``kidnappings'' are so common in the data is that this may be the formal charge filed against a man who elopes with a woman. Results are similar if we restrict the interaction term to cover sexual assaults (Appendix Table~\ref{tab:crimes_against_women_cm}).} Column 3 of Table~\ref{tab:bias_activated} shows that the interaction between an indicator for crimes against women and the in-group bias variable is small and statistically insignificant. Male defendants do not receive differential treatment from male and female judges, even in these cases.

Finally, in Table~\ref{tab:bias_activated} Column 4 we examine whether religious in-group bias emerges during the month of Ramadan, when Muslim religious identity may become particularly salient for both Muslims and non-Muslims.\footnote{Unlike the sample in \citet{Mehmood2020}, our sample only covers eight years, with Ramadan occurring only in the summer. There is thus no substantial time-series variation in daylight hours that can be exploited. Note that for this table only, we use the identity of the judge \textit{deciding} on the case, rather than the judge to whom it was assigned initially. Our implicit assumption is that the effect of Ramadan affects the outcome on the day the decision is reached, rather than on the day the case first appeared before a judge. See Section~\ref{sec:strategy} for more on how we treat cases seen by more than one judge.} The interaction between the Ramadan indicator and the in-group bias measure give a slightly positive coefficient but it is not statistically significant. This is different from \citep{Mehmood2020}, who do find effects of judge religious identity on decisions during Ramadan. Appendix Table~\ref{tab:bias_activated_cy} shows robustness of the estimates to using court-year instead of court-month fixed effects.\footnote{Religion is often a salient aspect of elections in India. A rigorous analysis of how elections affect judicial decision-making is beyond the scope of this paper. Our results are unchanged if we limit the sample to 2015--2018 (the post-national BJP period), and are similarly null if we partition the sample into 2-year bins (Appendix Table~\ref{tab:religion_by_year}).} 

We investigated religious violence, but we could not find datasets on religious violence that were well-matched to our sample period.\footnote{The primary dataset used for the study of religious violence is \citet{varshney2006}, which was updated by \citet{bhalotra2012} to 2010, the first year in our sample. The ACLED violence database covers India only from 2016; descriptions are in many cases too vague to identify Hindu-Muslim violence specifically or their perpetrators. While we did not find evidence of differential in-group bias in the week or month following local violence, the data quality is too low to treat the analysis as dispositive.} We show in Appendix Table~\ref{tab:election_month} that there is no differential in-group bias effect in election months. However, there is substantial variation in the extent to which in-group sentiments are primed across elections, so further research here is warranted.

\subsection{In-group Bias on the Basis of Caste}

We now consider one of the most important social cleavages in India: caste. Ideally, we would like to run an equivalent statistical test, where judge and defendant identity sometimes match on the caste dimension and sometimes do not. This is unfortunately infeasible for three reasons. First, unlike gender and religion, there is no classification for caste along which in- and out-groups can be confidently and universally defined. The two major categories of caste, \textit{varna} (four broad hierarchical categories, although hundreds of millions of Indians are \textit{avarna}, or having no \textit{varna}) and \textit{jati} (approximately 5,000 endogamous communities), are both insufficient in characterizing the affinities that people may feel within the caste system. For example, an upper caste person could identify with another upper caste person despite sharing neither \textit{varna} or \textit{jati}. Likewise, the term \textit{bahujan} is often used to describe the shared identity of marginalized groups such as Scheduled Castes and Other Backwards Castes. Second, individual names do not identify caste as precisely as they identify Islamic religion or gender identity and the caste significance of names can vary across regions.\footnote{For example, \citet{vahini2022} find 97\% accuracy in predicting religion from Indian names, but only 73\% even for broad caste categories like OBC/SC/ST. We have encountered similarly low accuracy in our own exercises. Given the need to match both judge and defendant, over half of our sample would be mis-classified at these rates.} Due to these limitations and to a lack of training data, we have not been able to develop a reliable correspondence between names and specific castes. Third, there are few district judges in the most identifiable caste categories: Scheduled Castes and Scheduled Tribes.

For these reasons, a direct analysis of in-group caste bias in the Indian judiciary is challenging. Instead, we analyze caste indirectly. Specifically, we follow \citet{fisman2017cultural} and define individuals as being in the same cultural group if they share a last name. As discussed in that paper and other work, shared last names are a noisy measure of caste similarity for many social groups. 

The measure is admittedly imperfect. Names are more numerous than castes, so members of the same caste usually have different last names. Further, sharing names can indicate greater affinity and closer social proximity than caste. Last names could signal similar socioeconomic status, for example, or shared religion. When a judge and defendant share a last name, they could even be relatives by blood or marriage. Individuals can also share a last name and be in different castes.

To determine whether judges deliver more favorable outcomes to defendants who share their last name, we estimate:
\begin{equation}
  \label{eq:lastname}
  \begin{split}
    Y_{i} = \beta_{1} \text{sameLastName}_{i} +  \phi_{ct(i)} + \zeta_{s(i)}  + X_i \delta + \epsilon_{i}\text{.}
  \end{split}
\end{equation}
where subscripts $i$, $s$ ,$c$ and $t$ are defined as above. The court-time ($\phi_{ct(i)}$) and act/section ($\zeta_s(i)$) fixed effects, and judge/defendant characteristics $X_i \delta$ are also as above. Further, we include additional fixed effects for judge and defendant last names and control for judge and defendant gender and religion. We limit the sample to individuals with last names that match at least one judge in their district at any time.\footnote{Without this limitation we have substantially more last name fixed effects in the sample but there is no additional variation in terms of identity match, because the \textit{sameLastName} variable always takes the value 0 for defendants whose last name never appears in the judge list.} 

The act/section fixed effects adjust for judge assignment rules based on the seriousness of the crime. Finally, the last name fixed effects adjust for the possibility that individuals from some social groups are more or less likely to be acquitted, and that judges in different social groups may have different average acquittal rates. The identification assumptions for consistent estimation of $\hat{\beta}_1$ are the same as in the prior section, and depend on random assignment of defendants to judges with any given last name within the court-time randomization block.\footnote{Appendix~\ref{appsec:name_balance} shows balance tests indicating that judges are no more or less likely to be assigned to defendants with the same last name.}

The results for last name bias are reported in Table~\ref{tab:last_name}. Columns 1 and 2 report unweighted estimates from Equation~\ref{eq:lastname}, comparable to the specifications in the previous sections. The point estimate of in-group bias is a precisely estimated zero.

An issue with the unweighted case-level regressions is that the sample is dominated by social groups with common last names. The results are thus driven by individuals with common last names, like \textit{Kumar} and \textit{Singh}. These are the names where a defendant-judge name match is the least likely to indicate shared caste. Matching on a common name may not indicate much cultural similarity, and the resulting estimates may not capture the experience of smaller caste groups. To address this issue, we estimate an alternate specification where sample weights treat each defendant last name group equally. Formally, we estimate weighted regressions where the weights are computed as the inverse of the number of defendants in the sample with each given last name. These regressions therefore describe variation in bias across \textit{groups}, rather than across individuals. 

The weighted regressions are reported in Columns 3 and 4, corresponding to the respective unweighted regressions in Columns 1 and 2. The weighted regressions show that a judge-defendant name match increases the likelihood of acquittal by about one percentage point ($p=0.11$ in Column 3). To directly test whether bias is driven by groups with less common names, we add a ``rare name'' interaction with the last name match indicator, where the ``rare name'' variable takes the value one if the defendant has a name with a below-median count in the data.\footnote{Results are similar whether we use the median across individuals or the median across groups. Out of 2,761,382 defendants with last names that appear at least once in the judge sample, 112,934 have rare names based on the individual median, and 1,376,640 have rare names based on the group median. These effects are robust to looser definitions of last name similarity (for example, treating \textit{Patil} and \textit{Patel} as similar).} Columns 5 and 6 report this specification. The uninteracted coefficient shows an absence of bias for common last names, and the interacted coefficient shows a 2 percentage point in-group bias for individuals with uncommon last names. The effect is not statistically significant in this specification ($p=0.14$), but the effects in Columns 3--6 are all statistically significant at the 5\% level in specifications with court-year fixed effects (Appendix Table~\ref{tab:last_name_loc_year}).\footnote{The effect sizes in the court-year specification are slightly larger, but not statistically distinguishable from those in the court-month specification.}

The effect size among individuals with uncommon names is economically relevant, representing about a 10--20\% increase in the probability of acquittal. Yet this bias is only seen for the relatively narrow social groups demarcated by less common names. By definition, then, the same-name effect is relevant only for a small share of the population. Groups with rare names are mechanically underrepresented in the population, and the likelihood of matching a judge with the same rare name is even smaller. This bias, therefore, while large in magnitude for some individuals, will be small in aggregate if it operates only at the level of narrow social groups.\footnote{Appendix Figure~\ref{fig:rare_names_app} shows how the interaction regression varies as a function of the threshold used to define rare names. The unweighted panel shows that the interaction terms become substantial and significant only for names outside of the 200 most common. About 10\% of defendants have names in this category, of whom about 1\% get assigned to judges with the same name---representing 2670 cases out of a sample of 2.6 million. Appendix Table~\ref{tab:name_list} shows the list of most common last names in the data.}

\subsubsection{Testing Caste Bias using Jati-associated names}

As discussed above, identifying jatis from individual names is challenging and error rates are high. In this section, we nevertheless analyze in-group bias using a name-jati correspondence that we have created from the People of India project, which was an effort from 1985--92 to comprehensively document all of India's social groups \citep{singh1992}. The People of India volumes include a list of common last names for every social group in every state. We matched these names to defendants and judges; we were able to match both in 8\% of cases. The match rate is low because the People of India do not describe a comprehensive set of names, and many names do not uniquely identify an individual to a jati. For about half of this sample, the People of India volumes identify the varna of the social group, allowing us to classify the group as Brahmin, Kshatriya, Vaishya, Shudra, Scheduled Caste or Scheduled Tribe.

We analyze this subsample for in-group bias, examining whether judges treat defendants favorably if they are from their same varna group. Recall that varna groups are broader than subcaste groups, but reflect an individual's hierarchy in the caste system. This is thus a test for favorable treatment of individuals with similar relative status in the caste system, even if they do not belong to exactly the same group.\footnote{While in principle we can also test same-jati effects in this dataset, the vast majority of jati matches are between individuals who also have the same last name. As such, this test would not be substantially different from that in Table~\ref{tab:last_name}.} 

Appendix Table~\ref{tab:caste_balance} provides a randomization balance test for the data subsample, showing that defendants from each varna are no more or less likely to be assigned to a judge from their same varna.\footnote{We use the word varna here loosely, by including SCs and STs who are outside the varna system.} Appendix Table~\ref{tab:caste_poi} shows that there is no evidence of in-group bias on the basis of varna. This is consistent with the findings above, as varna groups are much larger than jati groups; the in-group status of the defendant may thus not be particularly salient to judges.

The results in this section notwithstanding, we do not claim to rule out bias on the basis of caste among the broader population. Judges could be exhibiting in-group bias on the basis of cultural similarity measures that we are not able to observe, and as with our prior results, an absence of in-group bias does not rule out systematic bias against lower-caste defendants.

\section{Discussion and Conclusion}
\label{sec:conc}

Courts in developing countries face a number of special challenges, including cultural mismatch from transplanted legal codes, informal justice-system substitutes, citizen skepticism toward formal courts, insufficient human and physical capital investments in the court system, the inability of many individuals to pay for high-quality representation, implicit or explicit bias among members of the judiciary, and corruption \citep{DjankovLaPortaLopez-de-SilanesShleifer2003QJoE,LaPortaLopez-de-SilanesShleifer2008JoEL}. Yet with a few exceptions \citep[for example]{PonticelliAlencar2016TQJoE}, these characteristics of developing-country courts have been described only anecdotally. 

We make progress in this area by analyzing decisions in over 5 million criminal cases in India. We estimate robust, tight zero effects of judicial in-group bias along the dimensions of gender, religion, and caste. We do not find gender-based bias even when gender identity is more salient, nor does religious-based bias arise during festival periods, where religious identity may be heightened. We do find in-group bias among social groups with shared uncommon last names, suggesting that in-group bias can be magnified in circumstances where make the dimensions of shared (or unshared) identity are particularly salient. The aggregate effects of this bias are small, but they may be large for individual defendants.

The systematic null effects are surprising, especially given well-documented gender, caste, and religious in-group bias in non-judicial contexts in India. Two relevant examples are \citet{fisman2017cultural}, who find that credit offers and repayment rates rise when loan officers and clients have the same last name, and \citet{neggers2018}, who finds that random assignment of a minority election worker to a polling station has a large pro-minority effect on vote counts at that station. Our divergent findings raise the question of how these contexts differ from the judicial setting.  

One major difference is the judge's incentive structure. Judges expect little direct economic benefit or cost from seeing members of the out-group punished. That ``game'' is quite different from the cooperative context in \citet{fisman2017cultural} (where joint gains are possible through a successful loan), or the adversarial context in \citet{neggers2018} (where only one party can win an election).

A second relevant feature is the competing relevance of other identity factors. The judicial setting may make salient the class, education, or other status differences between judges and defendants, crowding out broader identity characteristics like religion and gender. In contrast, political competition for resources (as in \citet{neggers2018}) may magnify the salience of these identities. Similarly, \citet{sharan2020} finds that ethnic quotas in local government only improve public service delivery when lower-status groups occupy multiple positions in the political hierarchy. Consistent with this interpretation, our results on matching last names suggest that in-group bias is stronger under more narrow definitions of the in-group.

An example of both of these dynamics outside of judging is \citet{HannaLinden2012AEJEP}, who find no evidence of out-group animus (on the caste dimension) in the case of teachers grading student exams. Like judging, grading is a non-adversarial context, where teachers face flat incentives for how students are assessed. Further, there are impactful class and authority differences between teachers and students, which make differences due to caste less salient.

This discussion highlights the sensitivity of in-group bias to context. Further, it hints at a theoretical grounding for why results on in-group bias vary across different settings. Further empirical research drilling down on these theories will be valuable.

In the judicial setting, our null estimates of in-group bias contrast with findings in other jurisdictions, where researchers have tended to find large effects. To compare our estimates to those in the literature, we collect coefficients and standard errors from the studies of judge in-group bias that are most similar to ours. We identify every study we can find that focuses on measuring in-group bias among judges on a race, ethnicity, gender, or religious dimension, and that exploits an as-good-as-random judge or jury assignment mechanism for causal identification.\footnote{When papers report multiple specifications for the main effect, we use the effect size described most prominently in the text or described by the authors as the ``main specification.'' When papers have multiple outcomes, we use the outcome most similar to the acquittal or conviction rate, as in this study. If these are unavailable, we use the outcome most prominently described in the paper's abstract and introduction.} To make the studies comparable, we standardize effect sizes by dividing each in-group bias effect by the sample standard deviation of the outcome variable.  As shown in Figure~\ref{fig:literature} Panel A, our primary effect sizes on religion and gender are the smallest in the literature.  The high end of our confidence interval is an order of magnitude smaller than nearly all prior studies.

Another notable pattern in the graph is that the confidence intervals (and hence standard errors) grow with the effect sizes. A positive relationship between effect size and standard errors suggests that there could be publication bias in studies of judicial in-group bias, which would also help explain the distinctiveness of our null finding. To show this more directly, Figure~\ref{fig:literature} Panel B plots (in black triangles) the effect size of each of the previous studies against the standard error of the main estimated effect. For comparison, the estimates from our study are plotted as red circles. In the absence of publication bias or a design-based mechanical relationship between effect size and precision (such as adaptive sampling), study estimates should form a funnel that is centered around the true estimate.\footnote{ \citealp[See][]{egger1997bias,gerber2001testing,levine2009sample,slavin2009relationship,kuhberger2014publication,andrews2019bias}. A funnel shape is expected because studies with larger standard errors should produce a wider range of estimates that are symmetric around the true value.} The graphed estimates are evidently asymmetric, with many of the studies falling just outside the boundary defining statistical significance at the 5\% level.

To formally test for publication bias in prior studies, we follow the approach of \citet{andrews2019bias}. We estimate a publication function $p(z)$, describing the probability that a study is published as a function of the t-statistic $z$, the effect size divided by the effect standard error. This function can be identified up to a scale parameter, which we normalize under the assumption that all studies with $z > 1.96$ are published. This estimated function gives us a structural estimate, based on the existing published papers, for the likelihood of publication given a t-statistic $z$. The method also provides an adjusted effect size based on imputing unpublished studies.

Note that this method does not require all of these studies to estimate the same parameter --- this is essential, since the true amount of bias may differ substantially across settings, as we argue above. It only requires the approximate normality of parameter estimates, which is already implicit in the standard error calculations in most of these studies. Each study can be thought of as drawing a single parameter estimate, which is a noisy estimate of the true value in that particular setting. In the absence of publication bias, the expected value of the parameter estimate should not depend on the sample size; this is the null hypothesis of the \citet{andrews2019bias} test.

Table~\ref{tab:pub_bias} reports the result of the test for publication bias. Under the assumption that all positive, statistically significant studies are published, Columns 1--3 respectively show the probability that a study will get published, given a t-statistic in the ranges of $(-\infty, -1.96), (-1.96, 0), (0, 1.96)$, respectively. The estimates imply that studies with negative or statistically insignificant estimates are extremely unlikely to be published. Studies with results like ours --- statistically insignificant positive estimates --- are \textit{only 3\% as likely to be published} as studies with statistically significant positive results.

The estimates from prior literature are consistent with severe publication bias. The Column 5 estimate tells us that if all of these studies were estimating the same parameter, then accounting for publication bias would give us a true effect size of 0.046 SD, a fraction of the average observed effect size of 0.24 SD from the published studies. However, if these studies are all estimating different parameters due to their different contexts, then each of these estimates could be correct; instead, the publication bias exercise would suggest that there is a large volume of potential studies in contexts with no in-group bias which have not made it to the publication phase.\footnote{Indeed, since posting this paper, we have heard from more than one researcher who abandoned research on in-group bias when their preliminary results suggested a null result. Null or reverse effects of in-group bias do appear in other studies, but these studies focus on different aspects of their contexts and put little emphasis on the null in-group effects \citep{arnold2018racial,HannaLinden2012AEJEP}.}


The rest of the literature aside, our finding of a lack of in-group bias in India's lower courts does not rule out bias in the criminal justice system as a whole. Notwithstanding our results on acquittals, the legal system could still be biased against marginalized groups due to unequal geographic distribution of policing, discrimination in investigations, police/prosecutor decisions to file cases, the severity of charges applied, the severity of penalties imposed, the appeals process, civil litigation, or other factors. There could also be absolute bias, where both in- and out-group judges discriminate against out-groups. Our evidence suggests concerns about in-group bias might be better directed to parts of the justice pipeline other than judge acquittal decisions. 

More research is sorely needed to create an empirical basis for understanding the judicial process in India and in other developing countries. The expansion of publicly available datasets on judicial systems worldwide will be an important step in making this possible.

\clearpage 
\global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 90}

\begin{sidewaysfigure}
    \centering
    \caption{Summary statistics by crime category and defendant identity}
    \label{fig:summary}
    \begin{tabular}{@{}ll@{}}
        \hspace{10mm}   \textbf{{\small A. Female charged \% : Female population \% }} &      \hspace{10mm}   \textbf{ {\small B. Female -- male acquittal \% }} \\
        \includegraphics[width=.4\textwidth]{\curpath/exhibits/g_coef1} &
        \includegraphics[width=.4\textwidth]{\curpath/exhibits/g_coef2} \\
    \end{tabular}
    \begin{tabular}{@{}ll@{}}
        \hspace{10mm}   \textbf{{\small C. Muslim charged \% : Muslim population \% }} &      \hspace{10mm}   \textbf{ {\small D. Muslim -- non-Muslim acquittal \% }} \\
        \includegraphics[width=.4\textwidth]{\curpath/exhibits/r_coef1} &
        \includegraphics[width=.4\textwidth]{\curpath/exhibits/r_coef2} \\
    \end{tabular}

    \begin{minipage}{1.0\textwidth}
        {\scriptsize \emph{Notes:} Panel A shows the imbalance in the per capita rate of criminal charges by gender.  The share of cases with female defendants is divided by the share of women in the Indian population for each type of criminal charge. Panel C shows the same result for Muslims. Panel B shows the difference between female and male acquittal rates for each type of crime. Panel D shows the same difference between Muslims and non-Muslims. Crimes are ordered by maximal punishment, from most to least severe.
    
    \par}
    \end{minipage}
\end{sidewaysfigure}

\clearpage
\global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 0}

  \begin{table}%[ht]
    \begin{center}
      \caption{Summary statistics, by judge identity}
      \label{tab:judge_sam}
     \input{\curpath/exhibits/judge_summary}
    \begin{minipage}{0.95\textwidth}
    {\footnotesize \vspace{1mm}\emph{Notes:} Coefficients represent means for each variable in the sample, collapsed to the judge level. Standard errors reported in parentheses. \par} \vspace{1mm} 
   \end{minipage}
    \end{center}
  \end{table}

\clearpage
\global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 90}

\begin{sidewaystable}
    \begin{center}
        \caption{Impact of judge identity on defendant acquittal}
        \label{tab:random_acquittal}
        \input{\curpath/exhibits/gender_acquitted}
        \vspace{2mm}
        \input{\curpath/exhibits/religion_acquitted}
    \end{center}
    \begin{minipage}{1.3\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Panel A: Female judges; Panel B: Muslim judges.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification (Panel A): $Y_{i} = \beta_{1} \text{judgeMale}_{i} + \beta_{2} \text{defMale}_{i} + \beta_{3} \text{judgeMale}_{i} * \text{defMale}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$ \par
        Panel B uses an analogous specification, where $\text{judgeNonMuslim}_i$ and $\text{defNonMuslim}_i$ take the place of $\text{judgeMale}_i$ and $\text{defMale}_i$.
   \end{minipage}
\end{sidewaystable}

\clearpage 
\global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 0}

\begin{table}%[ht]
    \begin{center}
        \caption{In-group bias in contexts that activate identity}
      \label{tab:bias_activated}
      \resizebox{\linewidth}{!}{
        \input{\curpath/exhibits/victim_inter}
        }
  \begin{minipage}{\textwidth}
    \footnotesize \emph{Notes:}
    Regression results on whether in-group bias appears in a set of contexts that may make identity particularly salient. The contexts tested in each column are: (1) the defendant and victim have different religions; (2) the defendant and victim have different genders; (3) the case includes one or more charges considered crimes against women; (4) the judgment takes place during the month of Ramadan; and (5) the judgment takes place on the day of a Hindu festival (Dasara, Diwali, Holi or Rama Navami) or within the six following days. The type of bias considered is based on gender in Columns 1 and 3, and on religion in Columns 2, 4, and 5. Charge section fixed effects have been used across all reported columns. \\ 
   \end{minipage}
      \end{center}
\end{table}

\clearpage 

\begin{table}
  \begin{center}
    \caption{Effect of assignment to judge with same last name on defendant outcomes}
    \label{tab:last_name}
    
    \resizebox{\linewidth}{!}{
    \input{\curpath/exhibits/last_names}
  }
  \begin{minipage}{\textwidth}
    \scriptsize \emph{Notes:} This table reports results from a test of the effect of assignment to a judge with the same last name as the defendant on likelihood of acquittal (Equation~\ref{eq:lastname}). Court-month fixed effects, charge section fixed effects, and judge and defendant last name fixed effects have been used across all columns reported. Standard errors are clustered by judge.\\  
  \end{minipage}
    \end{center}
\end{table}


\clearpage

\begin{figure}%[htb!]
  \begin{center}
    \caption{Comparison with judicial bias estimates in other contexts}
    \label{fig:literature}
    \begin{subfigure}{\textwidth}
    \subcaption{\textbf{ A. Coefficient Plot}} \\ \vspace{2mm} \\
    \includegraphics[width=\linewidth]{\curpath/exhibits/lit_coef.png} \\ 
    \end{subfigure}
    \vspace{1cm}
    \begin{subfigure}{\textwidth}
    \subcaption{\textbf{B. Standardized Errors vs. Effect Sizes}} \\ 
    \includegraphics[scale=0.8]{\curpath/exhibits/pub_bias.pdf} \\
    \end{subfigure}
  \end{center}
   \begin{minipage}{1.0\textwidth}
   \scriptsize \emph{Notes:} This figure shows point estimates of in-group bias from other studies in the relevant literature. From the top, the coefficients of in-group bias (Panel A) correspond to \cite{grossman2016descriptive}, \cite{ShayoZussman2011QJE}, \cite{AnwarBayerHjalmarsson2012TQJoE}, 
    \cite{depew2017judges}, \cite{gazal2010let},
   \cite{knepper2018shadow}, \cite{sloane2019racial}, \cite{Didwania2018CLE}, \cite{lim2016judges}, and the main estimates from the present study respectively. \cite{shayo2017conflict} is excluded because the underlying data and variation overlap substantially with \cite{ShayoZussman2011QJE}. Panel B plots reported bias effects (Y axis) against effect standard errors. All effect sizes are standardized (dividing outcome variables by their standard deviation) to allow comparison across studies. From each table in this paper, we chose the specification with court-month and judge fixed effects. For contexts magnifying bias, we show the average effect for the group facing magnified bias. For example, for the Ramadan analysis, we show the sum of the bias coefficient and the bias * Ramadan coefficient, which describes religious in-group bias in the month of Ramadan.
   \par 
   \end{minipage}
\end{figure}

\clearpage


\begin{table}%[ht]
  \begin{center}
    \caption{Estimates of Publication Bias in Judicial In-Group Bias Studies}
    \label{tab:pub_bias}
   \input{\curpath/exhibits/pub_bias.tex}
    \begin{minipage}{1\textwidth}
      \footnotesize \vspace{1mm} \emph{Notes:} The table summarizes in-group bias in the judicial setting, measured across all papers we could find using randomized assignment of judges and juries, with adjustment for publication bias. Columns 1--4 respectively show the probability that a study gets published, given a t-statistic in the range of $(-\infty, -1.96]$, $(-1.96, 0]$, $(0, 1.96]$, and $(1.96,\infty)$ respectively. $\beta^*$ in Column 5 gives the true predicted average in-group bias effect after taking publication bias into account and imputing unpublished studies.  Estimates were calculated from the papers listed in Figure~\ref{fig:literature} (not including estimates from this paper), following \cite{andrews2019bias}.
    \end{minipage}
  \end{center}
\end{table}

\clearpage 

\begin{singlespace}
\bibliographystyle{apalike}
\bibliography{elliott,india}
\end{singlespace}

\clearpage

 
\begin{appendices}

\setcounter{figure}{0} 
\renewcommand{\thefigure}{A\arabic{figure}} 
\setcounter{table}{0} \renewcommand{\thetable}{A\arabic{table}} 


\section{Online Appendix: Additional Tables and Figures}

\begin{figure}[htp!]
 \centering
 \caption{India eCourts Case Record Sample}
 \includegraphics[width=0.7\textwidth]{\curpath/exhibits/ecourts_case_view.png}
 \label{fig:ecourts_case_view}
 \begin{minipage}{1.0\textwidth}
    {\scriptsize \emph{Notes:} The figure displays an anonymized version of a sample court record from \url{https://ecourts.gov.in/} for the District and Sessions Court of Vidisha. The `Petitioner and Advocate' and `Respondent and Advocate' sections contain the litigant names that we use for assigning gender and religion. The `Acts' section contains the data that allows us to discriminate between civil and criminal cases. We use the `Under Section(s)' column to infer the corresponding crime categories.\par}
 \end{minipage}
\end{figure}



\begin{figure}
    \centering
    \caption{Distribution of courts across districts in the analysis sample}
    \includegraphics[width=.7\textwidth]{\curpath/exhibits/court_map_rct} 
    \label{fig:court_maps}
     \begin{minipage}{1.0\textwidth}
    {\scriptsize \emph{Notes:} This figure shows the geographical distribution of the trial courts in our sample. Black lines delineate states, and within those the unit of observation for this graphical illustration are districts. Districts marked in white have no courts in our analysis.\par}
 \end{minipage}
\end{figure}


\newpage
\begin{figure}[htp!]
 \centering
 \caption{Sample accounting}
 \includegraphics[width=0.7\textwidth]{\curpath/exhibits/nomnoml.png}
 \label{fig:nomnoml}
 \begin{minipage}{1.0\textwidth}
    {\scriptsize \emph{Notes:} The figure displays the process through which we arrive at the analysis dataset from the parent dataset of 77 million legal case records. After restricting the sample to criminal cases, matching these criminal cases with our judge dataset, and dropping bail observations, 8.5 million case records remain. We can then assign the gender of the judge and defendant using our machine classifier for 6 million cases, and 6.6 million for religion. Finally, cases are dropped if they are seen in a court where only one judge is observed in a given month. This leaves 5.7 million cases in the religion analysis and 5.3 million in the gender analysis.\par}
 \end{minipage}
\end{figure}

\begin{figure}[htp!]
 \centering
 \caption{India eCourts Sample Judge Information inside the Search Engine}
 \includegraphics[width=0.7\textwidth]{\curpath/exhibits/ecourts_judge_scraping.png}
 \label{fig:ecourts_judge_scraping}
 \begin{minipage}{1.0\textwidth}
    {\scriptsize \emph{Notes:} Sample view of the eCourts court order search engine. We scraped the judge information implicitly given in the `Court Number' drop-down list of the search mask on --- in this case --- \url{https://services.ecourts.gov.in/ecourtindia_v4_bilingual/cases/s_order.php?state=D&state_cd=1&dist_cd=19} to obtain judge names and tenures.\par}
 \end{minipage}
\end{figure}

\begin{figure}
    \centering
    \caption{Distribution of Judge Fixed Effects: Acquittal Rate}
    \includegraphics[width=.7\textwidth]{\curpath/exhibits/judge_acquittal_resids} 
    \label{fig:judge_resids}
     \begin{minipage}{1.0\textwidth}
       {\scriptsize \emph{Notes:} This figure shows the distribution of judge fixed effects. We first regress the acquittal outcome on location-month and charge fixed effects, and calculate residuals. We then calculate the mean residual for each judge in the sample; this describes how the judge's mean acquittal rate differs from what would be predicted based on the charges and courts where that judge is observed. The sample size is 21,970 judges; the sample includes all cases with an unambiguous decision.\par}
 \end{minipage}
\end{figure}

\newpage
\begin{figure}
    \centering
    \caption{Effect of matching judge last name, alternate rare name thresholds}
    
    \panel{A. Weighted by inverse last name frequency}
    
\includegraphics[width=.7\textwidth]{\curpath/exhibits/rare_names_weighted}
    
    \panel{B. Unweighted}
    
    \includegraphics[width=.7\textwidth]{\curpath/exhibits/rare_names_unweighted}
    
    \label{fig:rare_names_app}
     \begin{minipage}{1.0\textwidth}
       {\scriptsize \emph{Notes:} This figure shows coefficients from alternate specifications of Table 6, Column 5. The regression shows that in-group bias on the basis of shared last name is only found for individuals with rare last names. Each pair of points shows (1) the uninteracted ``same last name'' coefficient (a triangle) and the interaction of the ``same last name'' with ``rare name'' (a circle). A rare name is defined as a name outside of the N most common names among defendants, where N is listed on the X axis. In Panel A, the regressions are weighted by inverse name frequency, such that each name gets equal weight. In Panel B, regressions are unweighted, so more weight is put on more common names.\par}
 \end{minipage}
\end{figure}
  
\newpage
\begin{table}
  \begin{center}
  \caption{Summary of Name Classifier Training Datasets}
  \label{tab:training}
  \input{\curpath/exhibits/training_dist.tex}
  \end{center}
   \begin{minipage}{1.0\textwidth}
    {\scriptsize \emph{Notes:} Panels A \& B of this table show the distribution of identities in the underlying training datasets of the gender and religion LSTM name classification models respectively.\par}
 \end{minipage}
\end{table}

\newpage
\begin{table}
  \begin{center}
  \caption{Share of analysis sample with classifiable names}
  \label{tab:drop_sample}
  
  \textbf{ {\small A. By crime type}} \\
  
    {\scriptsize  \input{\curpath/exhibits/table_crime_in_sample.tex}}

    \vspace{5mm}
    
  \textbf{\small B. By state} \\
    
    {\scriptsize \input{\curpath/exhibits/table_state_in_sample.tex}}
    
  \end{center}
   \begin{minipage}{1.0\textwidth}
     {\scriptsize \emph{Notes:} The tables show the share of the judge-matched sample with classifiable names, across crime type (Panel A) and states (Panel B).\par}
 \end{minipage}
\end{table}

\newpage
\begin{table}
  \begin{center}
  \caption{Gender and religion name classification rates by state}
  \label{tab:lstm_by_state}
  \input{\curpath/exhibits/class_success.tex}
  \end{center}
   \begin{minipage}{1.0\textwidth}
    {\scriptsize \emph{Notes:} The table shows the share of defendants whose names were unambiguously identified as male/female or Muslim/non-Muslim in each state, conditional on the case record having a non-missing defendant name.\par}
 \end{minipage}
\end{table}


\begin{landscape}
% \global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 90}

\begin{table}
\begin{center}
  \caption{Outcome variables mapped to dispositions}
  \label{tab:dispositions}
          \resizebox{0.9\linewidth}{!}{
  \input{\curpath/exhibits/dispositions}}
 \begin{minipage}{1.2\textwidth}
    {\scriptsize \emph{Notes:} 
    The second and third column indicate the number of cases and description corresponding to each disposition name in our analysis sample. The last three columns  illustrate the classification of the raw dispositions into our three outcome variables. In the table, no entry corresponds to the default value 0, and X denotes that the corresponding outcome value is set to 1. If a case has a disposition at all, the indicator variable \textit{Decision} equals 1, and 0 otherwise. If the disposition is clearly acquitted, the outcome variable \textit{Acquitted} takes the value 1, and 0 otherwise. The outcome variable for \textit{Conviction} has been coded analogously.\par}
 \end{minipage}
 \end{center}
\end{table}

\begin{table}
  \begin{center}
     \caption{Impact of assignment to a male judge on whether the disposition is ambiguous}
      \label{tab:robust_amb_female}
     \input{\curpath/exhibits/gender_amb}
    \end{center}
    \begin{minipage}{1.6\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Female judges, female defendants.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification: $Y_{i} = \beta_{1} \text{judgeMale}_{i} + \beta_{2} \text{defMale}_{i} + \beta_{3} \text{judgeMale}_{i} * \text{defMale}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$ \par
        The table validates the primary in-group gender bias test by reporting whether cases are differentially recorded with ambiguous outcomes when the judge \\ and defendant match identity. The setup is identical to Table~\ref{tab:random_acquittal}, but the outcome variable is an indicator for an ambiguous case outcome.
   \end{minipage}
\end{table}

\begin{table}[h!]
  \begin{center}
     \caption{Impact of assignment to a non-Muslim judge on whether the disposition is ambiguous}
      \label{tab:robust_amb_muslim}
     \input{\curpath/exhibits/religion_amb}
    \end{center}
    \begin{minipage}{1.6\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Muslim judges, Muslim defendants.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification: $Y_{i} = \beta_{1} \text{judgeNonMuslim}_{i} + \beta_{2} \text{defNonMuslim}_{i} + \beta_{3} \text{judgeNonMuslim}_{i} * \text{defNonMuslim}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$  \par
        The table validates the primary in-group religious bias test by reporting whether cases are differentially recorded with ambiguous outcomes when the judge \\ and defendant match identity. The setup is identical to Table~\ref{tab:random_acquittal}, but the outcome variable is an indicator for an ambiguous case outcome.
   \end{minipage}
\end{table}

% \begin{landscape}
% \global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 90}

\begin{table}
    \begin{center}
        \caption{Impact of assignment to a male judge on non-conviction}
        \label{tab:app_random_female}
        \input{\curpath/exhibits/gender_non_convicted}
    \end{center}
    \begin{minipage}{1.5\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Female judges.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification: $Y_{i} = \beta_{1} \text{judgeMale}_{i} + \beta_{2} \text{defMale}_{i} + \beta_{3} \text{judgeMale}_{i} * \text{defMale}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$ \par
        The table shows estimates of in-group gender bias. The setup is identical to Table~\ref{tab:random_acquittal}, but the outcome variable is an indicator for non-conviction \\ instead of for acquittal. These are distinct tests because they code ambiguous and undecided outcomes differently. In the main analysis, these are coded as negative outcomes (because they are not clear acquittals); here, they are coded as positive outcomes (because they are not clear convictions).
   \end{minipage}
\end{table}

\clearpage

\begin{table}
    \begin{center}
        \caption{Impact of assignment to a non-Muslim judge on rapid judicial decision}
        \label{tab:random_decision}
        \input{\curpath/exhibits/gender_decision}
        \vspace{2mm}
        \input{\curpath/exhibits/religion_decision}
    \end{center}
    \begin{minipage}{1.6\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Panel A: Female judges; Panel B: Muslim judges.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification (Panel A): $Y_{i} = \beta_{1} \text{judgeMale}_{i} + \beta_{2} \text{defMale}_{i} + \beta_{3} \text{judgeMale}_{i} * \text{defMale}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$  \par
        Panel B uses an analogous specification, where $\text{judgeNonMuslim}_i$ and $\text{defNonMuslim}_i$ take the place of $\text{judgeMale}_i$ and $\text{defMale}_i$.
   \end{minipage}
\end{table}

\begin{table}
  \begin{center}
     \caption{Impact of assignment to a male judge on acquittal rates, dropping ambiguous outcomes}
      \label{tab:amb_random_female}
     \input{\curpath/exhibits/gender_acquitted_amb}
    \end{center}
    \begin{minipage}{1.6\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Female judges.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification: $Y_{i} = \beta_{1} \text{judgeMale}_{i} + \beta_{2} \text{defMale}_{i} + \beta_{3} \text{judgeMale}_{i} * \text{defMale}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$ \par
        The table shows estimates of in-group gender bias. The setup is identical to Table~\ref{tab:random_acquittal}, but with ambiguous outcomes dropped.
   \end{minipage}
\end{table}

\begin{table}
  \begin{center}
     \caption{Impact of assignment to a non-Muslim judge on non-conviction}
      \label{tab:app_random_muslim}
     \input{\curpath/exhibits/religion_non_convicted}
    \end{center}
    \begin{minipage}{1.5\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Muslim judges, Muslim defendants.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification: $Y_{i} = \beta_{1} \text{judgeNonMuslim}_{i} + \beta_{2} \text{defNonMuslim}_{i} + \beta_{3} \text{judgeNonMuslim}_{i} * \text{defNonMuslim}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$  \par
        The table shows estimates of in-group religious bias. The setup is identical to Table~\ref{tab:random_acquittal}, but the outcome variable is an indicator for non-conviction instead \\ of for acquittal. These are distinct tests because they code ambiguous and undecided outcomes differently. In the main analysis, these are coded as negative outcomes (because they are not clear acquittals); here, they are coded as positive outcomes (because they are not clear convictions).
   \end{minipage}
\end{table}


\begin{table}
  \begin{center}
     \caption{Impact of assignment to a non-Muslim judge on acquittal rates,  dropping ambiguous outcomes}
      \label{tab:amb_random_muslim}
     \input{\curpath/exhibits/religion_acquitted_amb}
    \end{center}
    \begin{minipage}{1.6\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par 
        Reference group: Muslim judges, Muslim defendants.  \par
        Charge section fixed effects have been used across all columns reported. \par
        Specification: $Y_{i} = \beta_{1} \text{judgeNonMuslim}_{i} + \beta_{2} \text{defNonMuslim}_{i} + \beta_{3} \text{judgeNonMuslim}_{i} * \text{defNonMuslim}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$  \par
        The table shows estimates of in-group religious bias. The setup is identical to Table~\ref{tab:random_acquittal}, but with ambiguous outcomes dropped.
   \end{minipage}
\end{table}




\begin{table}
      \begin{center}
        \caption{Summary of charges, by gender of defendant}
        \label{tab:summary_gender}
        \resizebox{1\linewidth}{!}{
        \input{\curpath/exhibits/gbal.tex}}
    \end{center}
     \begin{minipage}{1.4\textwidth}
    {\scriptsize \emph{Notes:} Column 1 of this table reports the share of female defendants for each crime category. Column 2 reports the ratio of the female share for each crime to the female population share in India. Column 3 reports the acquittal rate for females accused of each crime category. Column 4 reports the analogous acquittal rates for males. Column 5 reports the difference in female and male acquittal rates for each crime category. Column 6 reports the total number of case records in each crime category. The total number of cases in this table is larger than the 6 million cases mentioned in \ref{fig:ecourts_case_view} as we also include cases records in the statistics where only the defendant gender is defined, even if the judge gender is unknown.\par}
 \end{minipage}
\end{table}

\begin{table}
      \begin{center}
        \caption{Summary of charges, by religion of defendant}
        \label{tab:summary_religion}
        \resizebox{1\linewidth}{!}{
        \input{\curpath/exhibits/rbal.tex}}
      \end{center}
        \begin{minipage}{1.4\textwidth}
    {\scriptsize \emph{Notes:} Column 1 of this table reports the share of Muslim defendants for each crime category. Column 2 reports the ratio of the Muslim share for each crime to the Muslim population share in India. Column 3 reports the acquittal rate for Muslims accused of each crime category. Column 4 reports the analogous acquittal rates for non-Muslims. Column 5 reports the difference in Muslim and non-Muslim acquittal rates for each crime category. Column 6 reports the total number of case records in each crime category. The total number of cases in this table is larger than the 6.6 million cases mentioned in \ref{fig:ecourts_case_view} as we also include cases records in the statistics where only the defendant religion is defined, even if the judge religion is unknown.\par}
 \end{minipage}
\end{table}

\end{landscape}

% \floatbarrier
\newpage
\begin{table}
      \begin{center}
        \caption{Distribution of cases by crime category and inclusion in various samples}
        \label{tab:summary_crime_cat}
        \resizebox{1\linewidth}{!}{
        \input{\curpath/exhibits/output_sample_accounting_1.tex}}
      \end{center}
        \begin{minipage}{1\textwidth}
          {\scriptsize \emph{Notes:} This table shows the share of cases in each of four samples, by crime type. Column 1 shows the full judicial dataset. Column 2 is the main analysis sample. Column 3 is the subsample where we observe defending and petitioning lawyers' gender and religious identities. Column 4 shows the sample that is matched to the People of India data, where judge and defendant varna can be identified.\par}
 \end{minipage}
\end{table}

% \floatbarrier
\newpage
\begin{table}
      \begin{center}
        \caption{Distribution of cases by state and inclusion in various samples}
        \label{tab:summary_state}
        \resizebox{1\linewidth}{!}{
        \input{\curpath/exhibits/output_sample_accounting_2.tex}}
      \end{center}
        \begin{minipage}{1\textwidth}
          {\scriptsize \emph{Notes:} This table shows the share of cases in each of four samples, by state. Column 1 shows the full judicial dataset. Column 2 is the main analysis sample. Column 3 is the subsample where we observe defending and petitioning lawyers' gender and religious identities. Column 4 shows the sample that is matched to the People of India data, where judge and defendant varna can be identified.\par}
 \end{minipage}
\end{table}

\newpage
\begin{table}[h!]
  \begin{center}
  \caption{Distribution of female and Muslim judges by crime category}
  \label{tab:judge_crime_cat}
  \input{\curpath/exhibits/table_judges_by_crime_category.tex}

\begin{minipage}{0.8\textwidth}
 {\footnotesize \vspace{2mm} Notes: This table shows the mean proportion of female and Muslim judges assigned to cases of different crime categories. }\\
      \end{minipage}
\end{center}
\end{table}

\clearpage
\begin{landscape}
    
\begin{table}
  \begin{center}
     \caption{In-group bias effects, limiting to courts/charges with few ambiguous outcomes}
      \label{tab:robust_amb_below}
     \input{\curpath/exhibits/low_ambiguity_rcts}
    \end{center}
    \begin{minipage}{1.4\textwidth}
        \footnotesize 
        \emph{Notes:} Standard errors in parentheses. \sym{*} \(p<0.10\), \sym{**} \(p<0.05\), \sym{***} \(p<0.01\).  \par
        The table reproduces the primary in-group bias specifications for gender, religion, and caste, but with the sample restricted to courts (odd-numbered columns) or charges (even-numbered columns) with below-median rates of outcomes being coded ambiguously. Columns 1--4 are analogous to Column 3 of Table~\ref{tab:random_acquittal}. Columns 5 and 6 are analogous to Column 2 of Table~\ref{tab:last_name}.
   \end{minipage}
\end{table}

\begin{table}[h!]
    \begin{center}
        \caption{In-group bias effects when judges and lawyers have same religion}
        \label{tab:lawyer_religion}
        \input{\curpath/exhibits/lawyers_religion}
        \begin{minipage}{1.25\textwidth}
            \footnotesize
            \emph{Notes:} These regressions extend our tests of in-group bias to examine cases where judges and lawyers have the same religion. Column 1 replicates the main analysis in Table~\ref{tab:random_acquittal} for the subset of cases where we observe both lawyers' names (and thus their religions). Column 2 tests for the effect of judge-defendant lawyer identity match, Column 3 for judge-petitioner lawyer, and Column 4 for both together. In-group bias is identified by the coefficient on ``judge and defendant'' in the first column ``judge and lawyer'' in the last three columns} \\
        \end{minipage}
    \end{center}
\end{table}

\begin{table}[h!]
  \begin{center}
     \caption{In-Group bias effects when judges and lawyers have same gender}
      \label{tab:lawyer_gender}
     \input{\curpath/exhibits/lawyers_gender}
    \begin{minipage}{1.2\textwidth}
        \footnotesize 
      \emph{Notes:} These regressions extend our tests of in-group bias to examine cases where judges and lawyers have the same gender. Column 1 replicates the main analysis in Table~\ref{tab:random_acquittal} for the subset of cases where we observe both lawyers' names (and thus their genders). Column 2 tests for the effect of judge-defendant lawyer identity match, Column 3 for judge-petitioner lawyer, and Column 4 for both together. In-group bias is identified by the coefficient on ``judge and defendant'' in the first column ``judge and lawyer'' in the last three columns} \\
          
   \end{minipage}
    \end{center}
  \end{table}

\end{landscape}

\clearpage
\begin{table}[H]
  \caption{In-group gender bias in contexts that activate identity: All coefficients} 
  \begin{center}
    \footnotesize{\input{\curpath/exhibits/victim_inter_all_g}}
  \label{tab:bias_activated_all_g}
  \begin{minipage}{0.95\textwidth}
    \footnotesize \emph{Notes:} This estimation is identical to the estimates of gender bias in contexts that activate gender identity displayed in Table~\ref{tab:bias_activated}, but all interaction coefficients are displayed for reference.
  \end{minipage}
  \end{center}
\end{table}

  % \floatbarrier
  \newpage
  
\begin{table}[H]
  \caption{In-group religion bias in contexts that activate identity: All coefficients} 
  \begin{center}
    \footnotesize{\input{\curpath/exhibits/victim_inter_all_r}}
  \label{tab:bias_activated_all_r}
  \begin{minipage}{\textwidth}
    \footnotesize \emph{Notes:} This estimation is identical to the estimates of religious bias in contexts that activate religious identity displayed in Table~\ref{tab:bias_activated}, but all interaction coefficients are displayed for reference.
  \end{minipage}
  \end{center}
\end{table}

  % \floatbarrier
  \newpage
  \begin{table}[h!]%[ht]
    \begin{center}
        \caption{In-group bias for sexual assault vs. other crimes against women}
      \label{tab:crimes_against_women_cm}
          \resizebox{\linewidth}{!}{
        \input{\curpath/exhibits/crimes_against_women.tex}
        }
  \begin{minipage}{\textwidth}
    \footnotesize \emph{Notes:}
    This table extends the specification in Column (3) of Table~\ref{tab:bias_activated}, which tests whether in-group gender bias is activated in cases involving crimes against women. Here we separately test for the subset of crimes against women which are sexual assaults. Column 1 shows results interacting crimes against women, excluding sexual assaults. Column 2 shows results interacting an indicator for cases where the most serious charge is a sexual assault. \\ 
   \end{minipage}
      \end{center}
    \end{table}

  \newpage
  % \end{landscape}
% \global\pdfpageattr\expandafter{\the\pdfpageattr/Rotate 0}

  \begin{table}[h!]%[ht]
    \begin{center}
        \caption{In-group bias in contexts that activate identity, court-year fixed effects}
      \label{tab:bias_activated_cy}
          \resizebox{\linewidth}{!}{
        \input{\curpath/exhibits/victim_inter_cy.tex}
        }
  \begin{minipage}{\textwidth}
    \footnotesize \emph{Notes:}
This table shows the same specifications as Table~\ref{tab:bias_activated}, but with court-year fixed effects. This tests whether in-group bias appears in a set of contexts that may make identity particularly salient. The context tested in each column is (1) the defendant and victim have different religions; (2) the defendant and victim have different genders; (3) the case includes one or more charges considered crimes against women; (4) the judgment takes place during the month of Ramadan; and (5) the judgment takes place on the day of a Hindu festival, either Dasara, Diwali, Holi or Rama Navami, or within the six following days. The type of bias considered is based on gender in Columns 1 and 3, and on religion in Columns 2, 4 and 5. Charge section fixed effects have been used across all reported columns. \\ 
   \end{minipage}
      \end{center}
    \end{table}

  % \floatbarrier
  \newpage
  \begin{table}[h!]%[ht]
    \begin{center}
        \caption{Religious in-group bias disaggregated by year}
      \label{tab:religion_by_year}
            \input{\curpath/exhibits/rct_2year_bins.tex}
  \begin{minipage}{1.1\textwidth}
    \footnotesize \emph{Notes:}
    This table extends the specification in Column (3) of Table~\ref{tab:bias_activated}, which tests whether in-group gender bias is activated in cases involving crimes against women. Here we separately test for the subset of crimes against women which are sexual assaults. Column 1 shows results interacting crimes against women, excluding sexual assaults. Column 2 shows results interacting an indicator for cases where the most serious charge is a sexual assault. \\ 
   \end{minipage}
      \end{center}
    \end{table}

  % \floatbarrier
  \newpage
  
\begin{table}[h!]
  \begin{center}
  \caption{Religious In-Group Bias in Election Months}
      \label{tab:election_month}
  \input{\curpath/exhibits/table_election_month}
  \end{center}
   \begin{minipage}{1.0\textwidth}
     {\scriptsize \emph{Notes:} The table shows the standard religious in-group bias specification, with an interaction for cases for which the final decision is made during an election month. The sample is smaller than the primary sample, because we drop cases which are ongoing, for which we cannot define the interaction variable. Column 1 uses the full sample, while Column 2 restricts to cases where the filling judge (for whom the judge religion indicator is defined) is the same as the deciding judge (for whom the election month indicator is defined). We define election month as any day that is within 15 days of the first polling date of a state election.
\par}
 \end{minipage}
\end{table}

  % \floatbarrier
  \newpage
  
\begin{table}[H]
  \caption{Effect on acquittal of matching judge's last name (court-year fixed effects)} 
  \begin{center}
   \footnotesize{\input{\curpath/exhibits/last_names_loc_year}}
   \label{tab:last_name_loc_year}
  \begin{minipage}{1.1\textwidth}
    \footnotesize \emph{Notes:} This table reports results from a test of the effect of assignment to a judge with the same last name as the defendant on likelihood of acquittal (Equation~\ref{eq:lastname}). Court-year fixed effects, charge section fixed effects, and judge and defendant last name fixed effects have been used across all columns reported. Standard errors are clustered by judge. The table is identical to Table~\ref{tab:last_name}, except it uses court-year rather than court-month fixed effects.
  \end{minipage}
  \end{center}
\end{table}

  \newpage
\begin{table}[H]
  \caption{Most common last names of defendants} 
  \begin{center}
   \footnotesize{\input{\curpath/exhibits/surname_freq_table}}
   \label{tab:name_list}
  \begin{minipage}{\textwidth}
    \footnotesize \emph{Notes:} This table shows the most common 30 last names in the defendants' data, along with other sample characteristics of those names.
  \end{minipage}
  \end{center}
\end{table}

\begin{landscape}
\begin{table}[h!]
    \begin{center}
      \caption{Balance checks on judge assignment across broad caste (varna) groups}
      \label{tab:caste_balance}
      \input{\curpath/exhibits/table_balance_poi.tex}
      \begin{minipage}{1.35\textwidth}
    {\footnotesize \emph{Notes:} This table reports results balance test on random assignment of judges to cases, based on broad caste, or varna, groups. Each column reports the likelihood of being assigned a judge of the same varna group as the defendant. Charge section and court-month fixed effects are used across all columns reported. Heteroskedasticity robust standard errors are reported below point estimates. } \\
      \end{minipage}
      \end{center}
   \end{table}
\end{landscape}

\clearpage
\newpage

% \floatbarrier
\begin{table}[h!]
  \begin{center}
    \vspace{-8mm}
  \caption{Impact of assignment to a judge with the same varna}  
      \label{tab:caste_poi}
  \resizebox{\textwidth}{!}{%
    \input{\curpath/exhibits/table_ingroup_poi.tex}
    }
    \end{center}
  \begin{center}\begin{minipage}{1.0\textwidth}
      \scriptsize
\vspace{-2mm}
      \emph{Notes:} 
      This table shows tests for in-group bias in judicial decisions on the basis of varna. The specification is similar to that in Table~\ref{tab:last_name}, but uses ``same varna'' as a match indicator rather than ``same last name.'' Court-month fixed effects, charge section fixed effects, and judge and defendant varna fixed effects are used in all columns. Varna groups are inferred from last names, based on matches to data from the People of India anthropological volumes. The sample is small because we have a low match rate between the case data and the People of India data. \par
    \end{minipage}
  \end{center}
\end{table}

%% \begin{figure}
%%       \centering
%%       \caption{Heterogeneity analysis of in-group bias, by crime category}
%%       \label{fig:crime_type}
%%             \begin{tabular}{@{}ll@{}}
%%         \includegraphics[width=.5\textwidth]{\curpath/exhibits/gender_crime_coef.png} &
%%         \includegraphics[width=.5\textwidth]{\curpath/exhibits/religion_crime_coef.png} \\
%%       \end{tabular}
%%       
%%   \begin{minipage}{1.0\textwidth}
%%     {\scriptsize \emph{Notes:} Each coefficient is drawn from the following regression specification for subsamples of specific crime categories:  $Y_{i} = \beta_{1} \text{judge[Male/NonMuslim]}_{i} + \beta_{2} \text{def[Male/NonMuslim]}_{i} + \beta_{3} \text{judge[Male/NonMuslim]}_{i} * \text{def[Male/NonMuslim]}_{i} + \phi_{ct(i)} + \zeta_{s(i)} + X_i \delta + \epsilon_{i}$
%%     Court-month, charge section and judge fixed effects are applied throughout. The coefficients represented in the figure correspond to $\beta_{3}$ in the specification. $\beta_{3}$ represents in-group gender bias in Panel A and in-group religious bias in Panel B, for each subsample.\par}
%%    \end{minipage}
%%   \end{figure}
  
\section{Online Appendix: Additional Detail on Methods and Data}

\subsection{Balance Tests}
\label{appsec:balance}

To test the validity of the random assignment of cases to judges, we run the following empirical balance test in the analysis sample:
\begin{equation}
\label{eq:random_female}
    \begin{split}
          \text{judgeFemale}_{i} = \beta_{1} \text{defFemale}_{i} + \beta_{2} \text{defMuslim}_{i}
          + \gamma \phi_{ct(i)} + \zeta_{s(i)} \\ + X_i \delta + \epsilon_{i}
    \end{split}
\end{equation}
with variables defined as above. The coefficients of interest are $\beta_{1}$ and $\gamma_{1}$, which respectively tell us whether female judges are more likely to adjudicate cases with female defendants. A similar specification is used for Muslim judges and Muslim defendants. Naturally, it would be desirable to include a range of defendant and case characteristics in these tests; unfortunately, the metadata available do not give us information about defendants besides their gender and religious identity. We view whether cases are decided during the sample period or classified with an unambiguous result as case outcomes and address them in the results.

Balance estimates are shown in Appendix Table~\ref{tab:balance}. Male and female defendants are equally likely to be assigned to female judges. Similarly, Muslim and non-Muslim defendants are equally likely to be assigned to Muslim judges. These balance tests provide support for our identification assumption of exogenous judge assignment.\footnote{The case metadata contains few other characteristics that can be used to test for balance. Appendix Table~\ref{tab:bal_miss} shows that judge identity is not substantively correlated with the observability of lawyer or defendant identities. While there are some significant entries in the table, the magnitudes are very small and we find precise zeroes on the in-group dimension (i.e. the effect of female judge on whether we observe a defendant's gender). Appendix Table \ref{tab:bal_lawyer_no_fe} shows correlations between lawyer and judge demographics --- there are non-zero correlations between petition lawyer gender and religion and judge gender, but these are not clear tests of random assignment, because the petitioner lawyer can change after the identity of the judge is known. Appendix Table~\ref{tab:bal_lawyer} presents our primary balance test (i.e. testing whether female/Muslim defendants are more likely to be heard by female/Muslim judges) in the subsample where we observe both defending and petitioning lawyers' gender and religious identities. As in the main sample, the evidence is consistent with random assignment.

  The table also shows that female defendants are more likely to have cases ruled on by Muslim judges, but the point effect is tiny (0.1 percentage points). Our main analysis (and these balance tests) are conditioned on state and charge fixed effects, because some charges are only seen by senior judges, who are less likely to be Muslim or female (Appendix Table~\ref{tab:judge_crime_cat}).}

\subsubsection{Balance Testing for Last Name Analysis}
\label{appsec:name_balance}

For our analysis of bias toward defendants with the same last names as judges, a different balance specification is required. For each last name in the judge sample, we test for balance by regressing an indicator for the judge having that last name on an indicator for a defendant having that last name, with the usual court-month and section fixed effects. We run this test for every last name that has at least one judge-defendant match. Appendix Figure~\ref{fig:last_name_balance} shows that the distribution of coefficients is concentrated around zero and that nearly all confidence intervals include zero.

\clearpage 

\begin{table}
\begin{center}
\caption{Balance test for assignment of judge identity}
\label{tab:balance}
\input{\curpath/exhibits/random_acq}
\begin{minipage}{0.95\textwidth}
   {\footnotesize \emph{Notes:} This table reports results from a balance test of random assignment of judges to cases in the study sample. For specification details, see Equation~\ref{eq:random_female}. Columns 1--2 report the likelihood of being assigned to a female judge relative to a male judge using court-month, and court-year fixed effects. Columns 3--4 report the likelihood of being assigned to a Muslim judge relative to a non-Muslim judge using court-month, and court-year fixed effects. Charge section fixed effects are used across all columns reported. Heteroskedasticity robust standard errors are reported below point estimates. } \\
\end{minipage}
\end{center}
\end{table}

% \floatbarrier
\newpage


%% EXTENDED BALANCE: LAWYERS' IDENTITY, AND DEFENDANT MISSINGNESS
\begin{table}
   \begin{center}
    \caption{Balance test for random assignment of judge identity: Missing information on identity}
    \label{tab:bal_miss}
    \resizebox{1\linewidth}{!}{
      \input{\curpath/exhibits/balance_extended_missing.tex}}
  \end{center}
  \begin{minipage}{\textwidth}
    {\scriptsize \emph{Notes:} The table shows whether missing information on defendant or lawyer identity is correlated with assignment to a female or Muslim judge. The specification is identical to that of Table~\ref{tab:balance}. \par}
  \end{minipage}
\end{table}

% \floatbarrier
\newpage

\begin{table}
  \begin{center}
    \caption{Balance test for random assignment of judge identity: lawyer characteristics}
    \label{tab:bal_lawyer_no_fe}
    \resizebox{1\linewidth}{!}{
      \input{\curpath/exhibits/balance_extended_lawyers.tex}
    }
    
    \begin{minipage}{\textwidth}
      {\scriptsize \emph{Notes:} The table shows whether defendants and lawyers with certain demographic characteristics are disproportionately assigned to either female or Muslim judges. The specification is identical to that of Table~\ref{tab:balance}. Note that we only observe lawyers' identity in the final judgment, so it is possible for defendants or prosecutors to change lawyers after learning of judge identity. As such, the lawyer rows cannot be interpreted as tests of random assignment.  \par}
    \end{minipage}
  \end{center}
\end{table}

\begin{table} [h!]
    \begin{center}
      \caption{Balance test for assignment of judge identity in subsample where we observe lawyers' identity}
    \label{tab:bal_lawyer}
     \input{\curpath/exhibits/balance_lawyers.tex}
     \begin{minipage}{0.95\textwidth}
   {\footnotesize \emph{Notes:} This table reports results from a balance test of random assignment of judges to cases in the subsample where we observe both defending and petitioning lawyers' religion and gender. For specification details, see Equation~\ref{eq:random_female}. Columns 1--2 report the likelihood of being assigned to a female judge relative to a male judge using court-month, and court-year fixed effects, respectively. Columns 3--4 report the likelihood of being assigned to a Muslim judge relative to a non-Muslim judge using court-month, and court-year fixed effects. Charge section fixed effects are used across all columns reported. Heteroskedasticity-robust standard errors are reported below point estimates. } \\
     \end{minipage}
     \end{center}
\end{table}

  \begin{figure}[h!]
    \centering
    \caption{Testing for random assignment of defendants to judges based on last names}
    \includegraphics[width=.7\textwidth]{\curpath/exhibits/name_balance_coef_rcap} 
    \label{fig:last_name_balance}
    \begin{minipage}{1.0\textwidth}
      {\scriptsize \emph{Notes:} This figure shows results from a test of whether defendants are more likely to be assigned to judges with the same last name as themselves. For each last name in the last name analysis sample, we regress an indicator for the judge having that name on an indicator for the defendant having that name. If the coefficient on the defendant indicator is positive, then defendants with that name are disproportionately likely to be matched to judges with that name. The graph shows that the distribution of estimates is centered around zero, very few are large in magnitude or significantly different from zero.\par}
    \end{minipage}
  \end{figure}

\end{appendices}

\end{document}
